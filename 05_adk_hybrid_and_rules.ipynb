{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 5: Hybrid Architectures and Rule-Based Agents\n",
    "\n",
    "## 🎯 Learning Objectives\n",
    "\n",
    "By the end of this lesson, you will be able to:\n",
    "\n",
    "1. **Understand** that \"agent\" doesn't always mean \"LLM\"\n",
    "2. **Create** rule-based agents using pure Python logic (no LLM calls)\n",
    "3. **Build** hybrid systems combining rules and LLMs intelligently\n",
    "4. **Optimize** costs by using rules for 70%+ of requests\n",
    "5. **Implement** LoopAgent for iterative workflows\n",
    "6. **Design** production-grade cost-effective architectures\n",
    "\n",
    "## 📚 Quick Recap: Lessons 1-4\n",
    "\n",
    "So far, you've learned:\n",
    "- ✅ LLM agents with tools (function calling)\n",
    "- ✅ Hierarchical routing (coordinator + specialists)\n",
    "- ✅ Sequential workflows (pipeline processing)\n",
    "- ✅ Parallel execution (concurrent information gathering)\n",
    "\n",
    "**All used LLM calls for decisions.** Now we'll learn when NOT to use LLMs!\n",
    "\n",
    "## 🚀 What's New: Rule-Based and Hybrid Patterns\n",
    "\n",
    "Not every decision needs an LLM:\n",
    "- 💰 **Rule-based agents**: $0.00 per request (pure Python logic)\n",
    "- 🎯 **Hybrid systems**: Rules + LLMs = best of both worlds\n",
    "- 🔄 **LoopAgent**: Iterative workflows with termination conditions\n",
    "\n",
    "## 🏢 Use Case: Cost-Optimized IT Support\n",
    "\n",
    "We'll build a production-grade IT support system that:\n",
    "- Uses rules for simple, predictable cases (70% of tickets)\n",
    "- Uses LLMs only when complexity requires it (30% of tickets)\n",
    "- Saves ~70% on API costs compared to all-LLM approach\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💡 Part 1: When Rules Beat LLMs\n",
    "\n",
    "### The LLM Tax\n",
    "\n",
    "Every LLM call costs:\n",
    "- 💸 **Money**: $0.0002+ per request (even gpt-5-nano)\n",
    "- ⏱️ **Time**: 500-2000ms latency\n",
    "- 🎲 **Variance**: Slight inconsistency in outputs\n",
    "\n",
    "### When Rules Are Better\n",
    "\n",
    "Use rule-based logic when:\n",
    "\n",
    "| Scenario | Rule-Based | LLM-Based |\n",
    "|----------|-----------|----------|\n",
    "| **Simple keyword matching** | ✅ Perfect | ❌ Overkill |\n",
    "| **Binary decisions** | ✅ Instant | ❌ Wasteful |\n",
    "| **Deterministic logic** | ✅ 100% consistent | ❌ Slight variation |\n",
    "| **High volume** | ✅ Scales cheaply | ❌ Expensive |\n",
    "| **Speed critical** | ✅ <10ms | ❌ 500ms+ |\n",
    "| **Complex reasoning** | ❌ Limited | ✅ Excellent |\n",
    "| **Nuanced understanding** | ❌ Can't handle | ✅ Best use case |\n",
    "\n",
    "### Real-World Hybrid Examples\n",
    "\n",
    "**E-commerce:**\n",
    "- Rules: \"out of stock\" → auto-response (90% of queries)\n",
    "- LLM: Complex product comparisons (10% of queries)\n",
    "\n",
    "**Customer Support:**\n",
    "- Rules: FAQ matching, business hours check (70%)\n",
    "- LLM: Complex troubleshooting, empathy required (30%)\n",
    "\n",
    "**IT Support (our use case):**\n",
    "- Rules: Simple keyword triage \"password\", \"wifi\", \"printer\" (70%)\n",
    "- LLM: Ambiguous or complex issues (30%)\n",
    "\n",
    "### Cost Comparison Example\n",
    "\n",
    "**10,000 daily tickets:**\n",
    "\n",
    "**All-LLM approach:**\n",
    "- 10,000 × 500 tokens × $0.0002/1K = **$1.00/day** = **$365/year**\n",
    "\n",
    "**Hybrid approach (70% rules, 30% LLM):**\n",
    "- Rules: 7,000 × $0 = **$0**\n",
    "- LLM: 3,000 × 500 tokens × $0.0002/1K = **$0.30/day** = **$110/year**\n",
    "- **Savings: $255/year (70%)**\n",
    "\n",
    "**The hybrid approach is a production best practice, not just a learning exercise!**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Part 2: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Google Agent Development Kit and dependencies\n",
    "!pip install -q google-adk litellm openai python-dotenv nest-asyncio\n",
    "\n",
    "print(\"✅ Packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core ADK imports - including BaseAgent for custom agents!\n",
    "from google.adk.agents import LlmAgent, BaseAgent, SequentialAgent, LoopAgent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "from google.genai import types\n",
    "\n",
    "# System imports\n",
    "import os\n",
    "import asyncio\n",
    "import time\n",
    "import re\n",
    "from typing import Dict, List, Any, AsyncGenerator\n",
    "from pydantic import Field\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "print(\"✅ Imports successful!\")\n",
    "print(\"   Key import: BaseAgent for creating rule-based agents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure OpenAI API key\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "    print(\"✅ API key loaded from Colab secrets\")\n",
    "except:\n",
    "    from getpass import getpass\n",
    "    print(\"💡 To use Colab secrets: Go to 🔑 (left sidebar) → Add new secret → Name: OPENAI_API_KEY\")\n",
    "    OPENAI_API_KEY = getpass(\"Enter your OpenAI API Key: \")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "if not OPENAI_API_KEY or OPENAI_API_KEY.strip() == \"\":\n",
    "    raise ValueError(\"❌ ERROR: No API key provided!\")\n",
    "\n",
    "print(\"✅ Authentication configured!\")\n",
    "\n",
    "# Model configuration\n",
    "OPENAI_MODEL = \"gpt-5-nano\"  # For LLM components only\n",
    "\n",
    "print(f\"\\n🤖 Model (for LLM agents): {OPENAI_MODEL}\")\n",
    "print(f\"💡 Rule-based agents: $0 (no API calls!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🎯 Part 3: Building Rule-Based Agents\n",
    "\n",
    "### What is a Rule-Based Agent?\n",
    "\n",
    "A rule-based agent:\n",
    "- Subclasses `BaseAgent` from ADK\n",
    "- Implements `_run_async_impl()` with pure Python logic\n",
    "- Makes **zero LLM calls**\n",
    "- Uses if/else, regex, keyword matching, etc.\n",
    "- Returns deterministic, instant results\n",
    "\n",
    "### Use Case: Keyword-Based Ticket Triage\n",
    "\n",
    "We'll create an agent that routes tickets based on simple keyword matching:\n",
    "- \"password\" → security_team\n",
    "- \"wifi\", \"network\", \"internet\" → network_team\n",
    "- \"laptop\", \"computer\", \"hardware\" → hardware_team\n",
    "- \"software\", \"application\", \"program\" → software_team\n",
    "\n",
    "No LLM needed for this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: Create Sample Ticket Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample tickets for testing\n",
    "SAMPLE_TICKETS = [\n",
    "    {\"id\": \"T-6001\", \"description\": \"I forgot my password and can't log in\"},\n",
    "    {\"id\": \"T-6002\", \"description\": \"The WiFi in my office is not working\"},\n",
    "    {\"id\": \"T-6003\", \"description\": \"My laptop screen is cracked\"},\n",
    "    {\"id\": \"T-6004\", \"description\": \"Microsoft Word keeps crashing when I open documents\"},\n",
    "    {\"id\": \"T-6005\", \"description\": \"I need help with something complicated and unusual\"},  # Fallback to LLM\n",
    "    {\"id\": \"T-6006\", \"description\": \"Can't connect to company VPN from home\"},\n",
    "    {\"id\": \"T-6007\", \"description\": \"Printer is jammed and won't print\"},\n",
    "    {\"id\": \"T-6008\", \"description\": \"Excel application won't start\"},\n",
    "]\n",
    "\n",
    "print(\"✅ Sample tickets loaded!\")\n",
    "print(f\"   Total tickets: {len(SAMPLE_TICKETS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2: Implement Rule-Based Triage Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuleBasedTriageAgent(BaseAgent):\n",
    "    \"\"\"\n",
    "    A rule-based agent that routes tickets using keyword matching.\n",
    "    Makes ZERO LLM calls - pure Python logic.\n",
    "    Fast, cheap, and deterministic.\n",
    "    \"\"\"\n",
    "    \n",
    "    routing_rules: Dict[str, List[str]] = Field(default_factory=dict)\n",
    "    def __init__(self, name: str = \"rule_triage\"):\n",
    "        super().__init__(name=name)\n",
    "        \n",
    "        # Define keyword rules for each team\n",
    "        self.routing_rules = {\n",
    "            \"security_team\": [\n",
    "                \"password\", \"login\", \"access\", \"credentials\", \n",
    "                \"locked out\", \"forgot password\", \"can't log in\",\n",
    "                \"authentication\", \"2fa\", \"mfa\"\n",
    "            ],\n",
    "            \"network_team\": [\n",
    "                \"wifi\", \"wi-fi\", \"network\", \"internet\", \"connection\",\n",
    "                \"vpn\", \"ethernet\", \"connectivity\", \"can't connect\",\n",
    "                \"slow internet\", \"no internet\"\n",
    "            ],\n",
    "            \"hardware_team\": [\n",
    "                \"laptop\", \"computer\", \"desktop\", \"monitor\", \"screen\",\n",
    "                \"keyboard\", \"mouse\", \"hardware\", \"device\", \"printer\",\n",
    "                \"physical\", \"broken\", \"cracked\", \"jammed\"\n",
    "            ],\n",
    "            \"software_team\": [\n",
    "                \"software\", \"application\", \"program\", \"app\",\n",
    "                \"microsoft\", \"excel\", \"word\", \"outlook\", \"teams\",\n",
    "                \"crash\", \"won't start\", \"won't open\", \"freezing\"\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    async def _run_async_impl(\n",
    "        self,\n",
    "        ctx: Any,\n",
    "    ) -> AsyncGenerator[Any, None]:\n",
    "        \"\"\"\n",
    "        Core logic: Route ticket based on keyword matching.\n",
    "        This is where the magic happens - no LLM calls!\n",
    "        \"\"\"\n",
    "        # Get the user's message from context\n",
    "        user_message = \"\"\n",
    "        if hasattr(ctx, 'new_message') and ctx.new_message:\n",
    "            if hasattr(ctx.new_message, 'parts') and ctx.new_message.parts:\n",
    "                user_message = ctx.new_message.parts[0].text\n",
    "        \n",
    "        print(f\"\\n🔍 [RULE-BASED TRIAGE] Analyzing: {user_message[:60]}...\")\n",
    "        \n",
    "        # Convert to lowercase for matching\n",
    "        message_lower = user_message.lower()\n",
    "        \n",
    "        # Check each team's keywords\n",
    "        team_scores = {}\n",
    "        for team, keywords in self.routing_rules.items():\n",
    "            score = sum(1 for keyword in keywords if keyword in message_lower)\n",
    "            if score > 0:\n",
    "                team_scores[team] = score\n",
    "        \n",
    "        # Determine routing\n",
    "        if team_scores:\n",
    "            # Route to team with highest score\n",
    "            best_team = max(team_scores, key=team_scores.get)\n",
    "            confidence = \"high\" if team_scores[best_team] >= 2 else \"medium\"\n",
    "            \n",
    "            response = f\"\"\"\n",
    "ROUTING: {best_team}\n",
    "CONFIDENCE: {confidence}\n",
    "MATCHED_KEYWORDS: {team_scores[best_team]}\n",
    "METHOD: Rule-based keyword matching\n",
    "COST: $0.00 (no LLM call)\n",
    "TIME: <10ms\n",
    "\n",
    "This ticket has been automatically routed to {best_team} based on keyword analysis.\n",
    "            \"\"\".strip()\n",
    "            \n",
    "            print(f\"✅ [RULE-BASED] Routed to: {best_team} (confidence: {confidence})\")\n",
    "        else:\n",
    "            # No clear match - escalate to LLM\n",
    "            response = f\"\"\"\n",
    "ROUTING: escalate_to_llm\n",
    "CONFIDENCE: low\n",
    "MATCHED_KEYWORDS: 0\n",
    "METHOD: No keyword matches found\n",
    "COST: $0.00 (rule check only)\n",
    "TIME: <10ms\n",
    "\n",
    "This ticket requires LLM analysis - no clear keyword matches found.\n",
    "Escalating to intelligent triage system.\n",
    "            \"\"\".strip()\n",
    "            \n",
    "            print(f\"⚠️  [RULE-BASED] No clear match - escalating to LLM\")\n",
    "        \n",
    "        # Yield the response as an event\n",
    "        response_content = types.Content(\n",
    "            role='model',\n",
    "            parts=[types.Part(text=response)]\n",
    "        )\n",
    "        \n",
    "        # Create a simple event object\n",
    "        class SimpleEvent:\n",
    "            def __init__(self, content):\n",
    "                self.content = content\n",
    "                self.partial = False\n",
    "                self.timestamp = datetime.now(timezone.utc)\n",
    "                class SimpleActions:\n",
    "                    def __init__(self):\n",
    "                        self.state_delta = {}\n",
    "                self.actions = SimpleActions()\n",
    "            \n",
    "            def is_final_response(self):\n",
    "                return True\n",
    "        \n",
    "        yield SimpleEvent(response_content)\n",
    "\n",
    "print(\"✅ Rule-Based Triage Agent created!\")\n",
    "print(\"   Cost per routing: $0.00\")\n",
    "print(\"   Speed: <10ms\")\n",
    "print(\"   Deterministic: 100% consistent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3: Test the Rule-Based Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the rule-based triage agent\n",
    "rule_triage = RuleBasedTriageAgent(name=\"keyword_triage\")\n",
    "\n",
    "# Setup runner\n",
    "rule_session_service = InMemorySessionService()\n",
    "RULE_APP = \"rule_triage_app\"\n",
    "\n",
    "rule_runner = Runner(\n",
    "    app_name=RULE_APP,\n",
    "    agent=rule_triage,\n",
    "    session_service=rule_session_service\n",
    ")\n",
    "\n",
    "print(\"✅ Rule-based system initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to test rule-based routing\n",
    "_rule_sessions = set()\n",
    "\n",
    "async def test_rule_routing_async(ticket: Dict, session_id: str = None):\n",
    "    \"\"\"Test rule-based routing for a ticket.\"\"\"\n",
    "    if session_id is None:\n",
    "        session_id = f\"rule_session_{ticket['id']}\"\n",
    "    \n",
    "    user_id = \"rule_system\"\n",
    "    \n",
    "    # Create session\n",
    "    session_key = (session_id, user_id)\n",
    "    if session_key not in _rule_sessions:\n",
    "        await rule_session_service.create_session(\n",
    "            app_name=RULE_APP,\n",
    "            user_id=user_id,\n",
    "            session_id=session_id,\n",
    "            state={}\n",
    "        )\n",
    "        _rule_sessions.add(session_key)\n",
    "    \n",
    "    content = types.Content(role='user', parts=[types.Part(text=ticket['description'])])\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"🎫 TICKET {ticket['id']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Description: {ticket['description']}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    events = rule_runner.run_async(user_id=user_id, session_id=session_id, new_message=content)\n",
    "    \n",
    "    final_response = None\n",
    "    async for event in events:\n",
    "        if event.is_final_response():\n",
    "            final_response = event.content.parts[0].text\n",
    "    \n",
    "    elapsed_time = (time.time() - start_time) * 1000  # Convert to ms\n",
    "    \n",
    "    if final_response:\n",
    "        print(f\"\\n📊 ROUTING RESULT:\")\n",
    "        print(f\"{'-'*80}\")\n",
    "        print(final_response)\n",
    "        print(f\"{'-'*80}\")\n",
    "        print(f\"⏱️  Processing time: {elapsed_time:.1f}ms\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return final_response\n",
    "\n",
    "def test_rule_routing(ticket: Dict, session_id: str = None):\n",
    "    \"\"\"Synchronous wrapper.\"\"\"\n",
    "    try:\n",
    "        loop = asyncio.get_running_loop()\n",
    "        import nest_asyncio\n",
    "        nest_asyncio.apply()\n",
    "        return asyncio.run(test_rule_routing_async(ticket, session_id))\n",
    "    except RuntimeError:\n",
    "        return asyncio.run(test_rule_routing_async(ticket, session_id))\n",
    "\n",
    "print(\"✅ Test function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4: Run Rule-Based Routing Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with various tickets\n",
    "for ticket in SAMPLE_TICKETS[:4]:  # Test first 4\n",
    "    test_rule_routing(ticket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5: Rule-Based Agent Key Observations\n",
    "\n",
    "**What you just saw:**\n",
    "\n",
    "1. ✅ **Zero LLM calls**: Pure Python keyword matching\n",
    "2. ✅ **Instant results**: <10ms response time\n",
    "3. ✅ **$0 cost**: No API charges whatsoever\n",
    "4. ✅ **100% deterministic**: Same input → same output always\n",
    "5. ✅ **Transparent logic**: You can see exactly why decisions were made\n",
    "6. ✅ **Escalation to LLM**: Handles edge cases gracefully\n",
    "\n",
    "**When to Use Rule-Based Agents:**\n",
    "- Clear, predictable patterns (keywords, thresholds)\n",
    "- High-volume, low-complexity decisions\n",
    "- Cost optimization is critical\n",
    "- Speed is essential (real-time requirements)\n",
    "- Determinism is required (compliance, auditing)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎨 Part 4: Hybrid Architecture - Best of Both Worlds\n",
    "\n",
    "### The Hybrid Strategy\n",
    "\n",
    "```\n",
    "            User Ticket\n",
    "                |\n",
    "                ▼\n",
    "        ┌───────────────┐\n",
    "        │ Rule-Based    │  ← Fast, free triage\n",
    "        │ Triage Agent  │     (70% of tickets)\n",
    "        └───────┬───────┘\n",
    "                │\n",
    "        ┌───────┴────────┐\n",
    "        │                │\n",
    "        ▼                ▼\n",
    "    Clear match?    No match?\n",
    "        │                │\n",
    "        ▼                ▼\n",
    "    Route to      LLM-Based\n",
    "    Team ($0)     Analysis\n",
    "                  ($0.0002)\n",
    "```\n",
    "\n",
    "### Use Case: Production IT Support System\n",
    "\n",
    "Let's build a complete hybrid system:\n",
    "1. **Rule triage** catches 70% of tickets (instant, free)\n",
    "2. **LLM fallback** handles complex cases (30% of tickets)\n",
    "3. **Specialist agents** resolve the issues\n",
    "\n",
    "This is how production systems actually work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1: Create LLM Fallback Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM-based triage for complex cases\n",
    "llm_triage = LlmAgent(\n",
    "    model=LiteLlm(model=f\"openai/{OPENAI_MODEL}\"),\n",
    "    name=\"llm_triage\",\n",
    "    instruction=\"\"\"\n",
    "    You are an intelligent IT support triage agent.\n",
    "    \n",
    "    YOUR TASK:\n",
    "    Analyze the ticket and determine which team should handle it:\n",
    "    - security_team: Password, authentication, access control issues\n",
    "    - network_team: Internet, WiFi, VPN, connectivity issues\n",
    "    - hardware_team: Physical devices, broken equipment\n",
    "    - software_team: Applications, programs, software crashes\n",
    "    \n",
    "    OUTPUT FORMAT:\n",
    "    ROUTING: [team_name]\n",
    "    CONFIDENCE: [high/medium/low]\n",
    "    REASONING: [brief explanation]\n",
    "    METHOD: LLM-based analysis\n",
    "    \n",
    "    Analyze the ticket carefully and use your reasoning to make the best routing decision.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(\"✅ LLM Triage Agent created!\")\n",
    "print(f\"   Model: {OPENAI_MODEL}\")\n",
    "print(f\"   Cost: ~$0.0002 per routing\")\n",
    "print(f\"   Use: Complex/ambiguous cases only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2: Build Hybrid Triage System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridTriageAgent(BaseAgent):\n",
    "    \"\"\"\n",
    "    Hybrid agent that tries rules first, falls back to LLM.\n",
    "    Optimizes for cost and speed.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, rule_agent: BaseAgent, llm_agent: LlmAgent, name: str = \"hybrid_triage\"):\n",
    "        super().__init__(name=name, sub_agents=[rule_agent, llm_agent])\n",
    "        self.rule_agent = rule_agent\n",
    "        self.llm_agent = llm_agent\n",
    "        self.stats = {\"rule_count\": 0, \"llm_count\": 0}\n",
    "    \n",
    "    async def _run_async_impl(self, ctx: Any) -> AsyncGenerator[Any, None]:\n",
    "        \"\"\"\n",
    "        Try rules first. If no match, use LLM.\n",
    "        \"\"\"\n",
    "        print(f\"\\n🔀 [HYBRID] Attempting rule-based triage first...\")\n",
    "        \n",
    "        # Try rule-based first\n",
    "        rule_response = None\n",
    "        async for event in self.rule_agent._run_async_impl(ctx):\n",
    "            if event.is_final_response():\n",
    "                rule_response = event.content.parts[0].text\n",
    "        \n",
    "        # Check if rule found a match\n",
    "        if rule_response and \"escalate_to_llm\" not in rule_response:\n",
    "            # Rule worked! Use it.\n",
    "            self.stats[\"rule_count\"] += 1\n",
    "            print(f\"✅ [HYBRID] Rule-based routing successful!\")\n",
    "            print(f\"   Cost: $0.00 | Stats: {self.stats['rule_count']} rule, {self.stats['llm_count']} LLM\")\n",
    "            \n",
    "            response_content = types.Content(\n",
    "                role='model',\n",
    "                parts=[types.Part(text=f\"[RULE-BASED ROUTING]\\n{rule_response}\")]\n",
    "            )\n",
    "        else:\n",
    "            # Need LLM\n",
    "            self.stats[\"llm_count\"] += 1\n",
    "            print(f\"⚡ [HYBRID] Escalating to LLM...\")\n",
    "            \n",
    "            # Run LLM agent\n",
    "            llm_response = None\n",
    "            # Create a runner for the LLM agent\n",
    "            llm_session_service = InMemorySessionService()\n",
    "            await llm_session_service.create_session(\n",
    "                app_name=\"llm_fallback\",\n",
    "                user_id=\"hybrid_system\",\n",
    "                session_id=\"llm_session\",\n",
    "                state={}\n",
    "            )\n",
    "            llm_runner = Runner(\n",
    "                app_name=\"llm_fallback\",\n",
    "                agent=self.llm_agent,\n",
    "                session_service=llm_session_service\n",
    "            )\n",
    "            \n",
    "            events = llm_runner.run_async(\n",
    "                user_id=\"hybrid_system\",\n",
    "                session_id=\"llm_session\",\n",
    "                new_message=ctx.new_message\n",
    "            )\n",
    "            \n",
    "            async for event in events:\n",
    "                if event.is_final_response():\n",
    "                    llm_response = event.content.parts[0].text\n",
    "            \n",
    "            print(f\"✅ [HYBRID] LLM routing complete!\")\n",
    "            print(f\"   Cost: ~$0.0002 | Stats: {self.stats['rule_count']} rule, {self.stats['llm_count']} LLM\")\n",
    "            \n",
    "            response_content = types.Content(\n",
    "                role='model',\n",
    "                parts=[types.Part(text=f\"[LLM-BASED ROUTING]\\n{llm_response}\")]\n",
    "            )\n",
    "        \n",
    "        # Create event\n",
    "        class SimpleEvent:\n",
    "            def __init__(self, content):\n",
    "                self.content = content\n",
    "                self.partial = False\n",
    "                self.timestamp = datetime.now(timezone.utc)\n",
    "                class SimpleActions:\n",
    "                    def __init__(self):\n",
    "                        self.state_delta = {}\n",
    "                self.actions = SimpleActions()\n",
    "            def is_final_response(self):\n",
    "                return True\n",
    "        \n",
    "        yield SimpleEvent(response_content)\n",
    "\n",
    "print(\"✅ Hybrid Triage Agent class created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hybrid system\n",
    "hybrid_triage = HybridTriageAgent(\n",
    "    rule_agent=rule_triage,\n",
    "    llm_agent=llm_triage,\n",
    "    name=\"cost_optimized_triage\"\n",
    ")\n",
    "\n",
    "# Setup runner\n",
    "hybrid_session_service = InMemorySessionService()\n",
    "HYBRID_APP = \"hybrid_triage_app\"\n",
    "\n",
    "hybrid_runner = Runner(\n",
    "    app_name=HYBRID_APP,\n",
    "    agent=hybrid_triage,\n",
    "    session_service=hybrid_session_service\n",
    ")\n",
    "\n",
    "print(\"✅ Hybrid System initialized!\")\n",
    "print(\"   Strategy: Try rules first, LLM fallback\")\n",
    "print(\"   Expected: 70% rule-based, 30% LLM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3: Test Hybrid System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper for testing hybrid system\n",
    "_hybrid_sessions = set()\n",
    "\n",
    "async def test_hybrid_routing_async(ticket: Dict, session_id: str = None):\n",
    "    \"\"\"Test hybrid routing.\"\"\"\n",
    "    if session_id is None:\n",
    "        session_id = f\"hybrid_session_{ticket['id']}\"\n",
    "    \n",
    "    user_id = \"hybrid_system\"\n",
    "    \n",
    "    session_key = (session_id, user_id)\n",
    "    if session_key not in _hybrid_sessions:\n",
    "        await hybrid_session_service.create_session(\n",
    "            app_name=HYBRID_APP,\n",
    "            user_id=user_id,\n",
    "            session_id=session_id,\n",
    "            state={}\n",
    "        )\n",
    "        _hybrid_sessions.add(session_key)\n",
    "    \n",
    "    content = types.Content(role='user', parts=[types.Part(text=ticket['description'])])\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"🎫 TICKET {ticket['id']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Description: {ticket['description']}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    events = hybrid_runner.run_async(user_id=user_id, session_id=session_id, new_message=content)\n",
    "    \n",
    "    final_response = None\n",
    "    async for event in events:\n",
    "        if event.is_final_response():\n",
    "            final_response = event.content.parts[0].text\n",
    "    \n",
    "    elapsed_time = (time.time() - start_time) * 1000\n",
    "    \n",
    "    if final_response:\n",
    "        print(f\"\\n📊 ROUTING RESULT:\")\n",
    "        print(f\"{'-'*80}\")\n",
    "        print(final_response)\n",
    "        print(f\"{'-'*80}\")\n",
    "        print(f\"⏱️  Total time: {elapsed_time:.1f}ms\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return final_response\n",
    "\n",
    "def test_hybrid_routing(ticket: Dict, session_id: str = None):\n",
    "    \"\"\"Synchronous wrapper.\"\"\"\n",
    "    try:\n",
    "        loop = asyncio.get_running_loop()\n",
    "        import nest_asyncio\n",
    "        nest_asyncio.apply()\n",
    "        return asyncio.run(test_hybrid_routing_async(ticket, session_id))\n",
    "    except RuntimeError:\n",
    "        return asyncio.run(test_hybrid_routing_async(ticket, session_id))\n",
    "\n",
    "print(\"✅ Hybrid test function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all tickets with hybrid system\n",
    "print(\"Testing all 8 tickets with hybrid triage...\\n\")\n",
    "\n",
    "for ticket in SAMPLE_TICKETS:\n",
    "    test_hybrid_routing(ticket)\n",
    "\n",
    "# Show final statistics\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"📊 HYBRID SYSTEM PERFORMANCE\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Rule-based routings: {hybrid_triage.stats['rule_count']} ({hybrid_triage.stats['rule_count']/len(SAMPLE_TICKETS)*100:.0f}%)\")\n",
    "print(f\"LLM-based routings: {hybrid_triage.stats['llm_count']} ({hybrid_triage.stats['llm_count']/len(SAMPLE_TICKETS)*100:.0f}%)\")\n",
    "print(f\"\\nCost analysis (per ticket):\")\n",
    "print(f\"  Rule-based: $0.00\")\n",
    "print(f\"  LLM-based: ~$0.0002\")\n",
    "print(f\"  Average: ${(hybrid_triage.stats['llm_count']/len(SAMPLE_TICKETS))*0.0002:.6f}\")\n",
    "print(f\"\\nVs. all-LLM approach: ${len(SAMPLE_TICKETS)*0.0002:.4f}\")\n",
    "savings = (1 - (hybrid_triage.stats['llm_count']/len(SAMPLE_TICKETS))) * 100\n",
    "print(f\"Cost savings: {savings:.0f}%\")\n",
    "print(f\"{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4: Hybrid Architecture Key Observations\n",
    "\n",
    "**What you just saw:**\n",
    "\n",
    "1. ✅ **Intelligent routing**: Rules handle ~70%, LLM handles ~30%\n",
    "2. ✅ **Cost optimization**: Significant savings vs all-LLM approach\n",
    "3. ✅ **Speed optimization**: Rules are instant, LLM only when needed\n",
    "4. ✅ **Best of both worlds**: Determinism + Intelligence\n",
    "5. ✅ **Transparent metrics**: See exactly what's using LLM calls\n",
    "\n",
    "**Production Scaling:**\n",
    "\n",
    "For 10,000 daily tickets:\n",
    "- All-LLM: 10,000 × $0.0002 = **$2.00/day** = $730/year\n",
    "- Hybrid (70/30): 3,000 × $0.0002 = **$0.60/day** = $219/year\n",
    "- **Annual savings: $511 (70%)**\n",
    "\n",
    "At scale, this matters!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔄 Part 5: LoopAgent for Iterative Workflows\n",
    "\n",
    "### What is LoopAgent?\n",
    "\n",
    "LoopAgent repeats a workflow until:\n",
    "- Max iterations reached, OR\n",
    "- Break condition met\n",
    "\n",
    "### Use Case: Iterative Troubleshooting\n",
    "\n",
    "IT support often requires iteration:\n",
    "1. Try solution A\n",
    "2. Check if problem solved\n",
    "3. If not, try solution B\n",
    "4. Repeat until fixed or max attempts\n",
    "\n",
    "Let's build this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1: Create Troubleshooting Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent that suggests solutions\n",
    "solution_suggester = LlmAgent(\n",
    "    model=LiteLlm(model=f\"openai/{OPENAI_MODEL}\"),\n",
    "    name=\"solution_suggester\",\n",
    "    instruction=\"\"\"\n",
    "    You are an IT troubleshooting expert.\n",
    "    \n",
    "    Given a problem description, suggest ONE specific troubleshooting step.\n",
    "    Each iteration, suggest a different approach if previous didn't work.\n",
    "    \n",
    "    OUTPUT FORMAT:\n",
    "    STEP: [step number]\n",
    "    ACTION: [specific action to try]\n",
    "    EXPECTED RESULT: [what should happen if this works]\n",
    "    \n",
    "    Common progression:\n",
    "    1. Simple restart/reconnect\n",
    "    2. Check settings/configuration\n",
    "    3. Update drivers/software\n",
    "    4. Advanced troubleshooting\n",
    "    5. Escalate to specialist\n",
    "    \n",
    "    Be specific and actionable.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Agent that checks if problem is solved\n",
    "solution_checker = LlmAgent(\n",
    "    model=LiteLlm(model=f\"openai/{OPENAI_MODEL}\"),\n",
    "    name=\"solution_checker\",\n",
    "    instruction=\"\"\"\n",
    "    You are evaluating if a troubleshooting step resolved the issue.\n",
    "    \n",
    "    For this simulation, use logic:\n",
    "    - Step 1-2: Usually don't solve complex issues (continue)\n",
    "    - Step 3: Often solves the problem (can stop)\n",
    "    - Step 4+: Definitely solved or needs escalation\n",
    "    \n",
    "    OUTPUT FORMAT:\n",
    "    SOLVED: [yes/no]\n",
    "    REASONING: [why you think it's solved or not]\n",
    "    RECOMMENDATION: [stop/continue/escalate]\n",
    "    \n",
    "    If you output SOLVED: yes, the loop should terminate.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(\"✅ Troubleshooting agents created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2: Create LoopAgent with Termination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a loop agent for iterative troubleshooting\n",
    "# Note: LoopAgent continues until max_iterations or manual break\n",
    "\n",
    "troubleshooting_loop = LoopAgent(\n",
    "    name=\"troubleshooting_loop\",\n",
    "    sub_agents=[\n",
    "        solution_suggester,\n",
    "        solution_checker\n",
    "    ],\n",
    "    max_iterations=5  # Safety limit\n",
    ")\n",
    "\n",
    "print(\"✅ LoopAgent created!\")\n",
    "print(f\"   Sub-agents: {len(troubleshooting_loop.sub_agents)}\")\n",
    "print(f\"   Max iterations: 5\")\n",
    "print(f\"   Strategy: Suggest → Check → Repeat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3: Test LoopAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup runner for loop agent\n",
    "loop_session_service = InMemorySessionService()\n",
    "LOOP_APP = \"loop_troubleshooting_app\"\n",
    "\n",
    "loop_runner = Runner(\n",
    "    app_name=LOOP_APP,\n",
    "    agent=troubleshooting_loop,\n",
    "    session_service=loop_session_service\n",
    ")\n",
    "\n",
    "print(\"✅ LoopAgent runner initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the loop agent\n",
    "async def test_loop_troubleshooting_async(problem: str):\n",
    "    \"\"\"Test iterative troubleshooting.\"\"\"\n",
    "    session_id = \"loop_test_session\"\n",
    "    user_id = \"loop_user\"\n",
    "    \n",
    "    await loop_session_service.create_session(\n",
    "        app_name=LOOP_APP,\n",
    "        user_id=user_id,\n",
    "        session_id=session_id,\n",
    "        state={}\n",
    "    )\n",
    "    \n",
    "    content = types.Content(role='user', parts=[types.Part(text=problem)])\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"🔄 ITERATIVE TROUBLESHOOTING\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Problem: {problem}\")\n",
    "    print(f\"\\n⏳ Starting iterative loop (max 5 iterations)...\\n\")\n",
    "    \n",
    "    events = loop_runner.run_async(user_id=user_id, session_id=session_id, new_message=content)\n",
    "    \n",
    "    iteration = 0\n",
    "    final_response = None\n",
    "    \n",
    "    async for event in events:\n",
    "        if event.is_final_response():\n",
    "            final_response = event.content.parts[0].text\n",
    "    \n",
    "    if final_response:\n",
    "        print(f\"\\n📊 TROUBLESHOOTING COMPLETE:\")\n",
    "        print(f\"{'-'*80}\")\n",
    "        print(final_response)\n",
    "        print(f\"{'-'*80}\")\n",
    "        print(f\"\\n✅ Loop terminated\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return final_response\n",
    "\n",
    "def test_loop_troubleshooting(problem: str):\n",
    "    \"\"\"Synchronous wrapper.\"\"\"\n",
    "    try:\n",
    "        loop = asyncio.get_running_loop()\n",
    "        import nest_asyncio\n",
    "        nest_asyncio.apply()\n",
    "        return asyncio.run(test_loop_troubleshooting_async(problem))\n",
    "    except RuntimeError:\n",
    "        return asyncio.run(test_loop_troubleshooting_async(problem))\n",
    "\n",
    "print(\"✅ Loop test function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a WiFi problem\n",
    "test_loop_troubleshooting(\"WiFi connection keeps dropping every few minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4: LoopAgent Key Observations\n",
    "\n",
    "**What you just saw:**\n",
    "\n",
    "1. ✅ **Iterative execution**: Agents run multiple times in sequence\n",
    "2. ✅ **Max iterations**: Safety mechanism prevents infinite loops\n",
    "3. ✅ **Stateful iteration**: Each iteration can build on previous\n",
    "4. ✅ **Termination conditions**: Can stop early if goal achieved\n",
    "5. ✅ **Real-world pattern**: Common in troubleshooting, optimization, refinement\n",
    "\n",
    "**When to Use LoopAgent:**\n",
    "- Iterative refinement (code review cycles, document editing)\n",
    "- Trial-and-error troubleshooting\n",
    "- Optimization problems (keep trying until good enough)\n",
    "- Multi-step verification (try, check, retry if needed)\n",
    "\n",
    "**Cost Consideration:**\n",
    "- Each iteration = 2 LLM calls (suggester + checker)\n",
    "- 5 iterations = 10 LLM calls total\n",
    "- Set max_iterations appropriately for your use case\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎓 Part 6: Student Exercises\n",
    "\n",
    "### Exercise 1: Enhance Rule-Based Triage (Intermediate)\n",
    "\n",
    "**Task:** Add priority detection to the rule-based agent.\n",
    "\n",
    "**Requirements:**\n",
    "1. Detect urgency keywords: \"urgent\", \"asap\", \"critical\", \"emergency\"\n",
    "2. Assign priority: critical/high/medium/low\n",
    "3. Include priority in routing decision\n",
    "4. Still maintain $0 cost (no LLM calls)\n",
    "\n",
    "**Hint:** Add another rules dictionary for priority keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Your code here\n",
    "\n",
    "# TODO: Extend RuleBasedTriageAgent with priority detection\n",
    "# class EnhancedRuleBasedTriageAgent(BaseAgent):\n",
    "#     def __init__(self, name: str = \"enhanced_rule_triage\"):\n",
    "#         super().__init__(name=name)\n",
    "#         # Add priority rules\n",
    "#         self.priority_rules = {\n",
    "#             \"critical\": [\"urgent\", \"emergency\", ...],\n",
    "#             ...\n",
    "#         }\n",
    "#     ...\n",
    "\n",
    "# TODO: Test with tickets containing urgency keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Cost Analysis Tool (Beginner)\n",
    "\n",
    "**Task:** Create a function that calculates cost savings for different hybrid ratios.\n",
    "\n",
    "**Requirements:**\n",
    "1. Function takes: daily_tickets, rule_percentage\n",
    "2. Calculates: all-LLM cost vs hybrid cost\n",
    "3. Shows: daily, monthly, annual savings\n",
    "4. Compare: 50%, 70%, 90% rule coverage\n",
    "\n",
    "**Goal:** Understand the economics of hybrid architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Your code here\n",
    "\n",
    "def calculate_hybrid_savings(daily_tickets: int, rule_percentage: float):\n",
    "    \"\"\"\n",
    "    Calculate cost savings of hybrid vs all-LLM approach.\n",
    "    \n",
    "    Args:\n",
    "        daily_tickets: Number of tickets per day\n",
    "        rule_percentage: Percentage handled by rules (0.0 to 1.0)\n",
    "    \"\"\"\n",
    "    # TODO: Implement cost calculation\n",
    "    # LLM cost per request: $0.0002\n",
    "    # Rule cost per request: $0.00\n",
    "    pass\n",
    "\n",
    "# TODO: Test with different scenarios\n",
    "# calculate_hybrid_savings(10000, 0.70)\n",
    "# calculate_hybrid_savings(10000, 0.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Build Custom Loop Logic (Advanced)\n",
    "\n",
    "**Task:** Create a custom agent that implements retry logic manually.\n",
    "\n",
    "**Requirements:**\n",
    "1. Subclass BaseAgent\n",
    "2. Implement custom retry logic in _run_async_impl\n",
    "3. Try an action up to 3 times\n",
    "4. Track success/failure\n",
    "5. Stop on first success\n",
    "\n",
    "**Challenge:** Implement this without using LoopAgent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Your code here\n",
    "\n",
    "# class CustomRetryAgent(BaseAgent):\n",
    "#     def __init__(self, action_agent: LlmAgent, max_retries: int = 3, name: str = \"retry_agent\"):\n",
    "#         super().__init__(name=name, sub_agents=[action_agent])\n",
    "#         self.action_agent = action_agent\n",
    "#         self.max_retries = max_retries\n",
    "#     \n",
    "#     async def _run_async_impl(self, ctx: Any) -> AsyncGenerator[Any, None]:\n",
    "#         # TODO: Implement retry logic\n",
    "#         for attempt in range(self.max_retries):\n",
    "#             # Try action\n",
    "#             # Check if successful\n",
    "#             # If success, break\n",
    "#             # Otherwise, retry\n",
    "#         ...\n",
    "\n",
    "# TODO: Test the retry logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📋 Part 7: Design Principles - Choosing the Right Approach\n",
    "\n",
    "### Decision Tree\n",
    "\n",
    "```\n",
    "Is the logic deterministic and rule-based?\n",
    "├─ YES → Use rule-based agent ($0, <10ms)\n",
    "└─ NO → Is it a simple decision?\n",
    "    ├─ YES → Try hybrid (rules first, LLM fallback)\n",
    "    └─ NO → Is complex reasoning required?\n",
    "        ├─ YES → Use LLM agent\n",
    "        └─ NO → Is iteration needed?\n",
    "            ├─ YES → Use LoopAgent\n",
    "            └─ NO → Use appropriate workflow pattern\n",
    "```\n",
    "\n",
    "### Pattern Selection Matrix\n",
    "\n",
    "| Pattern | Cost | Speed | Use When | Example |\n",
    "|---------|------|-------|----------|--------|\n",
    "| **Rule-based** | $0 | <10ms | Clear keywords/thresholds | \"password\" → security |\n",
    "| **Hybrid** | $0.0001 | 10-500ms | 70% simple, 30% complex | Try rules, fallback LLM |\n",
    "| **LLM** | $0.0002 | 500ms+ | Nuanced understanding | Complex reasoning |\n",
    "| **Sequential** | Nx cost | Nx time | Pipeline processing | Classify → Prioritize → Route |\n",
    "| **Parallel** | Nx cost | 1x time | Independent searches | Multi-source research |\n",
    "| **Loop** | Iteration × cost | Iteration × time | Trial-and-error | Troubleshooting steps |\n",
    "| **Hierarchical** | 1-2x cost | Variable | Complex triage | Route to specialist |\n",
    "\n",
    "### Cost Optimization Strategies\n",
    "\n",
    "**Layer 1: Rule-Based Filtering (70%)**\n",
    "- Handle obvious cases with keywords\n",
    "- Instant, free, deterministic\n",
    "- Example: FAQ matching, status checks\n",
    "\n",
    "**Layer 2: Hybrid Triage (20%)**\n",
    "- Rules couldn't decide confidently\n",
    "- Use cheap model (gpt-5-nano) for classification\n",
    "- Route to appropriate specialist\n",
    "\n",
    "**Layer 3: LLM Specialists (10%)**\n",
    "- Complex reasoning required\n",
    "- Use appropriate model for complexity\n",
    "- May use tools, multiple steps\n",
    "\n",
    "**Result: ~70-90% cost reduction vs all-LLM**\n",
    "\n",
    "### Production Best Practices\n",
    "\n",
    "1. **Start with rules**: Can you solve it without LLM?\n",
    "2. **Measure everything**: Track rule hit rate, LLM usage\n",
    "3. **Iterate on rules**: As patterns emerge, add more rules\n",
    "4. **Right-size models**: Don't use gpt-4o for simple tasks\n",
    "5. **Cache when possible**: Identical queries = cached responses\n",
    "6. **Set limits**: max_iterations, timeouts, fallbacks\n",
    "7. **Monitor costs**: Alert on unexpected LLM usage spikes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Part 8: Key Takeaways\n",
    "\n",
    "Congratulations! You've learned advanced production patterns!\n",
    "\n",
    "### What You Learned Today ✅\n",
    "\n",
    "1. **Rule-Based Agents**\n",
    "   - Subclass BaseAgent for custom logic\n",
    "   - $0 cost, <10ms speed\n",
    "   - Perfect for deterministic decisions\n",
    "   - 100% consistent and debuggable\n",
    "\n",
    "2. **Hybrid Architectures**\n",
    "   - Combine rules + LLMs intelligently\n",
    "   - 70-90% cost reduction possible\n",
    "   - Rules handle simple, LLM handles complex\n",
    "   - Production best practice, not theory\n",
    "\n",
    "3. **LoopAgent Pattern**\n",
    "   - Iterative workflows with max_iterations\n",
    "   - Useful for troubleshooting, refinement\n",
    "   - Built-in safety mechanisms\n",
    "   - Stateful iteration support\n",
    "\n",
    "4. **Design Principles**\n",
    "   - \"Agent\" ≠ \"LLM\" always\n",
    "   - Right tool for the job\n",
    "   - Cost-awareness in design\n",
    "   - Measure and optimize\n",
    "\n",
    "### Production Architecture Example\n",
    "\n",
    "```\n",
    "                    User Request\n",
    "                         |\n",
    "                         ▼\n",
    "                ┌─────────────────┐\n",
    "                │  Rule-Based     │  70% handled\n",
    "                │  Triage         │  Cost: $0\n",
    "                └────────┬────────┘\n",
    "                         │\n",
    "                ┌────────┴────────┐\n",
    "                │                 │\n",
    "           Clear match       No match\n",
    "                │                 │\n",
    "                ▼                 ▼\n",
    "         Route to Team    LLM Triage  30% handled\n",
    "         Cost: $0         Cost: $0.0002\n",
    "                                  │\n",
    "                                  ▼\n",
    "                          Specialist Agent\n",
    "                          Cost: $0.0002-0.0010\n",
    "\n",
    "Result: 70% savings, same quality\n",
    "```\n",
    "\n",
    "### Real-World Impact\n",
    "\n",
    "**Startup (1,000 daily tickets):**\n",
    "- All-LLM: $73/year\n",
    "- Hybrid: $22/year\n",
    "- Savings: $51/year\n",
    "\n",
    "**Scale-up (10,000 daily tickets):**\n",
    "- All-LLM: $730/year\n",
    "- Hybrid: $219/year\n",
    "- Savings: $511/year\n",
    "\n",
    "**Enterprise (100,000 daily tickets):**\n",
    "- All-LLM: $7,300/year\n",
    "- Hybrid: $2,190/year\n",
    "- Savings: $5,110/year\n",
    "\n",
    "**At scale, architecture matters!**\n",
    "\n",
    "### Complete ADK Pattern Library 🎨\n",
    "\n",
    "You now know:\n",
    "1. **Basic agents** (Lesson 1): LLM agents with personality\n",
    "2. **Tools** (Lesson 2): Function calling\n",
    "3. **Hierarchical routing** (Lesson 3): Coordinator + specialists\n",
    "4. **Sequential workflows** (Lesson 4): Pipeline processing\n",
    "5. **Parallel execution** (Lesson 4): Concurrent operations\n",
    "6. **Rule-based agents** (Lesson 5): Zero-cost deterministic logic\n",
    "7. **Hybrid systems** (Lesson 5): Cost-optimized architectures\n",
    "8. **Loop patterns** (Lesson 5): Iterative workflows\n",
    "\n",
    "### Next Steps 🚀\n",
    "\n",
    "You're ready to build production systems! Consider:\n",
    "- Persistent state (Firestore)\n",
    "- Error handling and retries\n",
    "- Monitoring and observability\n",
    "- MCP integration\n",
    "- Production deployment\n",
    "\n",
    "### Resources 📚\n",
    "\n",
    "- [ADK Custom Agents](https://google.github.io/adk-docs/agents/custom-agents/)\n",
    "- [ADK LoopAgent](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/)\n",
    "- [ADK Documentation](https://google.github.io/adk-docs/)\n",
    "\n",
    "---\n",
    "\n",
    "### 🎓 Final Challenge\n",
    "\n",
    "Build a complete production IT support system that:\n",
    "1. Uses rule-based triage for 70%+ of tickets\n",
    "2. Falls back to LLM for complex cases\n",
    "3. Routes to appropriate specialist agents\n",
    "4. Implements retry logic for failed actions\n",
    "5. Tracks and reports cost metrics\n",
    "\n",
    "**You now have all the tools to build cost-effective, production-grade AI systems! 🎉**\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
