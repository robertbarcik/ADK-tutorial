{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 5: Hybrid Architectures and Rule-Based Agents\n",
    "\n",
    "## ğŸ¯ Learning Objectives\n",
    "\n",
    "By the end of this lesson, you will be able to:\n",
    "\n",
    "1. **Understand** that \"agent\" doesn't always mean \"LLM\"\n",
    "2. **Create** rule-based agents using pure Python logic (no LLM calls)\n",
    "3. **Build** hybrid systems combining rules and LLMs intelligently\n",
    "4. **Optimize** costs by using rules for 70%+ of requests\n",
    "5. **Implement** LoopAgent for iterative workflows\n",
    "6. **Design** production-grade cost-effective architectures\n",
    "\n",
    "## ğŸ“š Quick Recap: Lessons 1-4\n",
    "\n",
    "So far, you've learned:\n",
    "- âœ… LLM agents with tools (function calling)\n",
    "- âœ… Hierarchical routing (coordinator + specialists)\n",
    "- âœ… Sequential workflows (pipeline processing)\n",
    "- âœ… Parallel execution (concurrent information gathering)\n",
    "\n",
    "**All used LLM calls for decisions.** Now we'll learn when NOT to use LLMs!\n",
    "\n",
    "## ğŸš€ What's New: Rule-Based and Hybrid Patterns\n",
    "\n",
    "Not every decision needs an LLM:\n",
    "- ğŸ’° **Rule-based agents**: $0.00 per request (pure Python logic)\n",
    "- ğŸ¯ **Hybrid systems**: Rules + LLMs = best of both worlds\n",
    "- ğŸ”„ **LoopAgent**: Iterative workflows with termination conditions\n",
    "\n",
    "## ğŸ¢ Use Case: Cost-Optimized IT Support\n",
    "\n",
    "We'll build a production-grade IT support system that:\n",
    "- Uses rules for simple, predictable cases (70% of tickets)\n",
    "- Uses LLMs only when complexity requires it (30% of tickets)\n",
    "- Saves ~70% on API costs compared to all-LLM approach\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¡ Part 1: When Rules Beat LLMs\n",
    "\n",
    "### The LLM Tax\n",
    "\n",
    "Every LLM call costs:\n",
    "- ğŸ’¸ **Money**: $0.0002+ per request (even gpt-5-nano)\n",
    "- â±ï¸ **Time**: 500-2000ms latency\n",
    "- ğŸ² **Variance**: Slight inconsistency in outputs\n",
    "\n",
    "### When Rules Are Better\n",
    "\n",
    "Use rule-based logic when:\n",
    "\n",
    "| Scenario | Rule-Based | LLM-Based |\n",
    "|----------|-----------|----------|\n",
    "| **Simple keyword matching** | âœ… Perfect | âŒ Overkill |\n",
    "| **Binary decisions** | âœ… Instant | âŒ Wasteful |\n",
    "| **Deterministic logic** | âœ… 100% consistent | âŒ Slight variation |\n",
    "| **High volume** | âœ… Scales cheaply | âŒ Expensive |\n",
    "| **Speed critical** | âœ… <10ms | âŒ 500ms+ |\n",
    "| **Complex reasoning** | âŒ Limited | âœ… Excellent |\n",
    "| **Nuanced understanding** | âŒ Can't handle | âœ… Best use case |\n",
    "\n",
    "### Real-World Hybrid Examples\n",
    "\n",
    "**E-commerce:**\n",
    "- Rules: \"out of stock\" â†’ auto-response (90% of queries)\n",
    "- LLM: Complex product comparisons (10% of queries)\n",
    "\n",
    "**Customer Support:**\n",
    "- Rules: FAQ matching, business hours check (70%)\n",
    "- LLM: Complex troubleshooting, empathy required (30%)\n",
    "\n",
    "**IT Support (our use case):**\n",
    "- Rules: Simple keyword triage \"password\", \"wifi\", \"printer\" (70%)\n",
    "- LLM: Ambiguous or complex issues (30%)\n",
    "\n",
    "### Cost Comparison Example\n",
    "\n",
    "**10,000 daily tickets:**\n",
    "\n",
    "**All-LLM approach:**\n",
    "- 10,000 Ã— 500 tokens Ã— $0.0002/1K = **$1.00/day** = **$365/year**\n",
    "\n",
    "**Hybrid approach (70% rules, 30% LLM):**\n",
    "- Rules: 7,000 Ã— $0 = **$0**\n",
    "- LLM: 3,000 Ã— 500 tokens Ã— $0.0002/1K = **$0.30/day** = **$110/year**\n",
    "- **Savings: $255/year (70%)**\n",
    "\n",
    "**The hybrid approach is a production best practice, not just a learning exercise!**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ Part 2: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Google Agent Development Kit and dependencies\n",
    "!pip install -q google-adk litellm openai python-dotenv nest-asyncio\n",
    "\n",
    "print(\"âœ… Packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core ADK imports - including BaseAgent for custom agents!\n",
    "from google.adk.agents import LlmAgent, BaseAgent, SequentialAgent, LoopAgent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "from google.genai import types\n",
    "\n",
    "# System imports\n",
    "import os\n",
    "import asyncio\n",
    "import time\n",
    "import re\n",
    "from typing import Dict, List, Any, AsyncGenerator\n",
    "from pydantic import Field\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "print(\"âœ… Imports successful!\")\n",
    "print(\"   Key import: BaseAgent for creating rule-based agents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure OpenAI API key\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "    print(\"âœ… API key loaded from Colab secrets\")\n",
    "except:\n",
    "    from getpass import getpass\n",
    "    print(\"ğŸ’¡ To use Colab secrets: Go to ğŸ”‘ (left sidebar) â†’ Add new secret â†’ Name: OPENAI_API_KEY\")\n",
    "    OPENAI_API_KEY = getpass(\"Enter your OpenAI API Key: \")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "if not OPENAI_API_KEY or OPENAI_API_KEY.strip() == \"\":\n",
    "    raise ValueError(\"âŒ ERROR: No API key provided!\")\n",
    "\n",
    "print(\"âœ… Authentication configured!\")\n",
    "\n",
    "# Model configuration\n",
    "OPENAI_MODEL = \"gpt-5-nano\"  # For LLM components only\n",
    "\n",
    "print(f\"\\nğŸ¤– Model (for LLM agents): {OPENAI_MODEL}\")\n",
    "print(f\"ğŸ’¡ Rule-based agents: $0 (no API calls!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ Part 3: Building Rule-Based Agents\n",
    "\n",
    "### What is a Rule-Based Agent?\n",
    "\n",
    "A rule-based agent:\n",
    "- Subclasses `BaseAgent` from ADK\n",
    "- Implements `_run_async_impl()` with pure Python logic\n",
    "- Makes **zero LLM calls**\n",
    "- Uses if/else, regex, keyword matching, etc.\n",
    "- Returns deterministic, instant results\n",
    "\n",
    "### Use Case: Keyword-Based Ticket Triage\n",
    "\n",
    "We'll create an agent that routes tickets based on simple keyword matching:\n",
    "- \"password\" â†’ security_team\n",
    "- \"wifi\", \"network\", \"internet\" â†’ network_team\n",
    "- \"laptop\", \"computer\", \"hardware\" â†’ hardware_team\n",
    "- \"software\", \"application\", \"program\" â†’ software_team\n",
    "\n",
    "No LLM needed for this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: Create Sample Ticket Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample tickets for testing\n",
    "SAMPLE_TICKETS = [\n",
    "    {\"id\": \"T-6001\", \"description\": \"I forgot my password and can't log in\"},\n",
    "    {\"id\": \"T-6002\", \"description\": \"The WiFi in my office is not working\"},\n",
    "    {\"id\": \"T-6003\", \"description\": \"My laptop screen is cracked\"},\n",
    "    {\"id\": \"T-6004\", \"description\": \"Microsoft Word keeps crashing when I open documents\"},\n",
    "    {\"id\": \"T-6005\", \"description\": \"I need help with something complicated and unusual\"},  # Fallback to LLM\n",
    "    {\"id\": \"T-6006\", \"description\": \"Can't connect to company VPN from home\"},\n",
    "    {\"id\": \"T-6007\", \"description\": \"Printer is jammed and won't print\"},\n",
    "    {\"id\": \"T-6008\", \"description\": \"Excel application won't start\"},\n",
    "]\n",
    "\n",
    "print(\"âœ… Sample tickets loaded!\")\n",
    "print(f\"   Total tickets: {len(SAMPLE_TICKETS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2: Implement Rule-Based Triage Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuleBasedTriageAgent(BaseAgent):\n",
    "    \"\"\"\n",
    "    A rule-based agent that routes tickets using keyword matching.\n",
    "    Makes ZERO LLM calls - pure Python logic.\n",
    "    Fast, cheap, and deterministic.\n",
    "    \"\"\"\n",
    "    \n",
    "    routing_rules: Dict[str, List[str]] = Field(default_factory=dict)\n",
    "    def __init__(self, name: str = \"rule_triage\"):\n",
    "        super().__init__(name=name)\n",
    "        \n",
    "        # Define keyword rules for each team\n",
    "        self.routing_rules = {\n",
    "            \"security_team\": [\n",
    "                \"password\", \"login\", \"access\", \"credentials\", \n",
    "                \"locked out\", \"forgot password\", \"can't log in\",\n",
    "                \"authentication\", \"2fa\", \"mfa\"\n",
    "            ],\n",
    "            \"network_team\": [\n",
    "                \"wifi\", \"wi-fi\", \"network\", \"internet\", \"connection\",\n",
    "                \"vpn\", \"ethernet\", \"connectivity\", \"can't connect\",\n",
    "                \"slow internet\", \"no internet\"\n",
    "            ],\n",
    "            \"hardware_team\": [\n",
    "                \"laptop\", \"computer\", \"desktop\", \"monitor\", \"screen\",\n",
    "                \"keyboard\", \"mouse\", \"hardware\", \"device\", \"printer\",\n",
    "                \"physical\", \"broken\", \"cracked\", \"jammed\"\n",
    "            ],\n",
    "            \"software_team\": [\n",
    "                \"software\", \"application\", \"program\", \"app\",\n",
    "                \"microsoft\", \"excel\", \"word\", \"outlook\", \"teams\",\n",
    "                \"crash\", \"won't start\", \"won't open\", \"freezing\"\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    async def _run_async_impl(\n",
    "        self,\n",
    "        ctx: Any,\n",
    "    ) -> AsyncGenerator[Any, None]:\n",
    "        \"\"\"\n",
    "        Core logic: Route ticket based on keyword matching.\n",
    "        This is where the magic happens - no LLM calls!\n",
    "        \"\"\"\n",
    "        # Get the user's message from context\n",
    "        user_message = \"\"\n",
    "        if hasattr(ctx, 'new_message') and ctx.new_message:\n",
    "            if hasattr(ctx.new_message, 'parts') and ctx.new_message.parts:\n",
    "                user_message = ctx.new_message.parts[0].text\n",
    "        \n",
    "        print(f\"\\nğŸ” [RULE-BASED TRIAGE] Analyzing: {user_message[:60]}...\")\n",
    "        \n",
    "        # Convert to lowercase for matching\n",
    "        message_lower = user_message.lower()\n",
    "        \n",
    "        # Check each team's keywords\n",
    "        team_scores = {}\n",
    "        for team, keywords in self.routing_rules.items():\n",
    "            score = sum(1 for keyword in keywords if keyword in message_lower)\n",
    "            if score > 0:\n",
    "                team_scores[team] = score\n",
    "        \n",
    "        # Determine routing\n",
    "        if team_scores:\n",
    "            # Route to team with highest score\n",
    "            best_team = max(team_scores, key=team_scores.get)\n",
    "            confidence = \"high\" if team_scores[best_team] >= 2 else \"medium\"\n",
    "            \n",
    "            response = f\"\"\"\n",
    "ROUTING: {best_team}\n",
    "CONFIDENCE: {confidence}\n",
    "MATCHED_KEYWORDS: {team_scores[best_team]}\n",
    "METHOD: Rule-based keyword matching\n",
    "COST: $0.00 (no LLM call)\n",
    "TIME: <10ms\n",
    "\n",
    "This ticket has been automatically routed to {best_team} based on keyword analysis.\n",
    "            \"\"\".strip()\n",
    "            \n",
    "            print(f\"âœ… [RULE-BASED] Routed to: {best_team} (confidence: {confidence})\")\n",
    "        else:\n",
    "            # No clear match - escalate to LLM\n",
    "            response = f\"\"\"\n",
    "ROUTING: escalate_to_llm\n",
    "CONFIDENCE: low\n",
    "MATCHED_KEYWORDS: 0\n",
    "METHOD: No keyword matches found\n",
    "COST: $0.00 (rule check only)\n",
    "TIME: <10ms\n",
    "\n",
    "This ticket requires LLM analysis - no clear keyword matches found.\n",
    "Escalating to intelligent triage system.\n",
    "            \"\"\".strip()\n",
    "            \n",
    "            print(f\"âš ï¸  [RULE-BASED] No clear match - escalating to LLM\")\n",
    "        \n",
    "        # Yield the response as an event\n",
    "        response_content = types.Content(\n",
    "            role='model',\n",
    "            parts=[types.Part(text=response)]\n",
    "        )\n",
    "        \n",
    "        # Create a simple event object\n",
    "        class SimpleEvent:\n",
    "            def __init__(self, content):\n",
    "                self.content = content\n",
    "                self.partial = False\n",
    "                self.timestamp = datetime.now(timezone.utc)\n",
    "                class SimpleActions:\n",
    "                    def __init__(self):\n",
    "                        self.state_delta = {}\n",
    "                self.actions = SimpleActions()\n",
    "            \n",
    "            def is_final_response(self):\n",
    "                return True\n",
    "        \n",
    "        yield SimpleEvent(response_content)\n",
    "\n",
    "print(\"âœ… Rule-Based Triage Agent created!\")\n",
    "print(\"   Cost per routing: $0.00\")\n",
    "print(\"   Speed: <10ms\")\n",
    "print(\"   Deterministic: 100% consistent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3: Test the Rule-Based Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the rule-based triage agent\n",
    "rule_triage = RuleBasedTriageAgent(name=\"keyword_triage\")\n",
    "\n",
    "# Setup runner\n",
    "rule_session_service = InMemorySessionService()\n",
    "RULE_APP = \"rule_triage_app\"\n",
    "\n",
    "rule_runner = Runner(\n",
    "    app_name=RULE_APP,\n",
    "    agent=rule_triage,\n",
    "    session_service=rule_session_service\n",
    ")\n",
    "\n",
    "print(\"âœ… Rule-based system initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to test rule-based routing\n",
    "_rule_sessions = set()\n",
    "\n",
    "async def test_rule_routing_async(ticket: Dict, session_id: str = None):\n",
    "    \"\"\"Test rule-based routing for a ticket.\"\"\"\n",
    "    if session_id is None:\n",
    "        session_id = f\"rule_session_{ticket['id']}\"\n",
    "    \n",
    "    user_id = \"rule_system\"\n",
    "    \n",
    "    # Create session\n",
    "    session_key = (session_id, user_id)\n",
    "    if session_key not in _rule_sessions:\n",
    "        await rule_session_service.create_session(\n",
    "            app_name=RULE_APP,\n",
    "            user_id=user_id,\n",
    "            session_id=session_id,\n",
    "            state={}\n",
    "        )\n",
    "        _rule_sessions.add(session_key)\n",
    "    \n",
    "    content = types.Content(role='user', parts=[types.Part(text=ticket['description'])])\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ğŸ« TICKET {ticket['id']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Description: {ticket['description']}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    events = rule_runner.run_async(user_id=user_id, session_id=session_id, new_message=content)\n",
    "    \n",
    "    final_response = None\n",
    "    async for event in events:\n",
    "        if event.is_final_response():\n",
    "            final_response = event.content.parts[0].text\n",
    "    \n",
    "    elapsed_time = (time.time() - start_time) * 1000  # Convert to ms\n",
    "    \n",
    "    if final_response:\n",
    "        print(f\"\\nğŸ“Š ROUTING RESULT:\")\n",
    "        print(f\"{'-'*80}\")\n",
    "        print(final_response)\n",
    "        print(f\"{'-'*80}\")\n",
    "        print(f\"â±ï¸  Processing time: {elapsed_time:.1f}ms\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return final_response\n",
    "\n",
    "def test_rule_routing(ticket: Dict, session_id: str = None):\n",
    "    \"\"\"Synchronous wrapper.\"\"\"\n",
    "    try:\n",
    "        loop = asyncio.get_running_loop()\n",
    "        import nest_asyncio\n",
    "        nest_asyncio.apply()\n",
    "        return asyncio.run(test_rule_routing_async(ticket, session_id))\n",
    "    except RuntimeError:\n",
    "        return asyncio.run(test_rule_routing_async(ticket, session_id))\n",
    "\n",
    "print(\"âœ… Test function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4: Run Rule-Based Routing Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with various tickets\n",
    "for ticket in SAMPLE_TICKETS[:4]:  # Test first 4\n",
    "    test_rule_routing(ticket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5: Rule-Based Agent Key Observations\n",
    "\n",
    "**What you just saw:**\n",
    "\n",
    "1. âœ… **Zero LLM calls**: Pure Python keyword matching\n",
    "2. âœ… **Instant results**: <10ms response time\n",
    "3. âœ… **$0 cost**: No API charges whatsoever\n",
    "4. âœ… **100% deterministic**: Same input â†’ same output always\n",
    "5. âœ… **Transparent logic**: You can see exactly why decisions were made\n",
    "6. âœ… **Escalation to LLM**: Handles edge cases gracefully\n",
    "\n",
    "**When to Use Rule-Based Agents:**\n",
    "- Clear, predictable patterns (keywords, thresholds)\n",
    "- High-volume, low-complexity decisions\n",
    "- Cost optimization is critical\n",
    "- Speed is essential (real-time requirements)\n",
    "- Determinism is required (compliance, auditing)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¨ Part 4: Hybrid Architecture - Best of Both Worlds\n",
    "\n",
    "### The Hybrid Strategy\n",
    "\n",
    "```\n",
    "            User Ticket\n",
    "                |\n",
    "                â–¼\n",
    "        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "        â”‚ Rule-Based    â”‚  â† Fast, free triage\n",
    "        â”‚ Triage Agent  â”‚     (70% of tickets)\n",
    "        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                â”‚\n",
    "        â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "        â”‚                â”‚\n",
    "        â–¼                â–¼\n",
    "    Clear match?    No match?\n",
    "        â”‚                â”‚\n",
    "        â–¼                â–¼\n",
    "    Route to      LLM-Based\n",
    "    Team ($0)     Analysis\n",
    "                  ($0.0002)\n",
    "```\n",
    "\n",
    "### Use Case: Production IT Support System\n",
    "\n",
    "Let's build a complete hybrid system:\n",
    "1. **Rule triage** catches 70% of tickets (instant, free)\n",
    "2. **LLM fallback** handles complex cases (30% of tickets)\n",
    "3. **Specialist agents** resolve the issues\n",
    "\n",
    "This is how production systems actually work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1: Create LLM Fallback Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM-based triage for complex cases\n",
    "llm_triage = LlmAgent(\n",
    "    model=LiteLlm(model=f\"openai/{OPENAI_MODEL}\"),\n",
    "    name=\"llm_triage\",\n",
    "    instruction=\"\"\"\n",
    "    You are an intelligent IT support triage agent.\n",
    "    \n",
    "    YOUR TASK:\n",
    "    Analyze the ticket and determine which team should handle it:\n",
    "    - security_team: Password, authentication, access control issues\n",
    "    - network_team: Internet, WiFi, VPN, connectivity issues\n",
    "    - hardware_team: Physical devices, broken equipment\n",
    "    - software_team: Applications, programs, software crashes\n",
    "    \n",
    "    OUTPUT FORMAT:\n",
    "    ROUTING: [team_name]\n",
    "    CONFIDENCE: [high/medium/low]\n",
    "    REASONING: [brief explanation]\n",
    "    METHOD: LLM-based analysis\n",
    "    \n",
    "    Analyze the ticket carefully and use your reasoning to make the best routing decision.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(\"âœ… LLM Triage Agent created!\")\n",
    "print(f\"   Model: {OPENAI_MODEL}\")\n",
    "print(f\"   Cost: ~$0.0002 per routing\")\n",
    "print(f\"   Use: Complex/ambiguous cases only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2: Build Hybrid Triage System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridTriageAgent(BaseAgent):\n",
    "    \"\"\"\n",
    "    Hybrid agent that tries rules first, falls back to LLM.\n",
    "    Optimizes for cost and speed.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, rule_agent: BaseAgent, llm_agent: LlmAgent, name: str = \"hybrid_triage\"):\n",
    "        super().__init__(name=name, sub_agents=[rule_agent, llm_agent])\n",
    "        self.rule_agent = rule_agent\n",
    "        self.llm_agent = llm_agent\n",
    "        self.stats = {\"rule_count\": 0, \"llm_count\": 0}\n",
    "    \n",
    "    async def _run_async_impl(self, ctx: Any) -> AsyncGenerator[Any, None]:\n",
    "        \"\"\"\n",
    "        Try rules first. If no match, use LLM.\n",
    "        \"\"\"\n",
    "        print(f\"\\nğŸ”€ [HYBRID] Attempting rule-based triage first...\")\n",
    "        \n",
    "        # Try rule-based first\n",
    "        rule_response = None\n",
    "        async for event in self.rule_agent._run_async_impl(ctx):\n",
    "            if event.is_final_response():\n",
    "                rule_response = event.content.parts[0].text\n",
    "        \n",
    "        # Check if rule found a match\n",
    "        if rule_response and \"escalate_to_llm\" not in rule_response:\n",
    "            # Rule worked! Use it.\n",
    "            self.stats[\"rule_count\"] += 1\n",
    "            print(f\"âœ… [HYBRID] Rule-based routing successful!\")\n",
    "            print(f\"   Cost: $0.00 | Stats: {self.stats['rule_count']} rule, {self.stats['llm_count']} LLM\")\n",
    "            \n",
    "            response_content = types.Content(\n",
    "                role='model',\n",
    "                parts=[types.Part(text=f\"[RULE-BASED ROUTING]\\n{rule_response}\")]\n",
    "            )\n",
    "        else:\n",
    "            # Need LLM\n",
    "            self.stats[\"llm_count\"] += 1\n",
    "            print(f\"âš¡ [HYBRID] Escalating to LLM...\")\n",
    "            \n",
    "            # Run LLM agent\n",
    "            llm_response = None\n",
    "            # Create a runner for the LLM agent\n",
    "            llm_session_service = InMemorySessionService()\n",
    "            await llm_session_service.create_session(\n",
    "                app_name=\"llm_fallback\",\n",
    "                user_id=\"hybrid_system\",\n",
    "                session_id=\"llm_session\",\n",
    "                state={}\n",
    "            )\n",
    "            llm_runner = Runner(\n",
    "                app_name=\"llm_fallback\",\n",
    "                agent=self.llm_agent,\n",
    "                session_service=llm_session_service\n",
    "            )\n",
    "            \n",
    "            events = llm_runner.run_async(\n",
    "                user_id=\"hybrid_system\",\n",
    "                session_id=\"llm_session\",\n",
    "                new_message=ctx.new_message\n",
    "            )\n",
    "            \n",
    "            async for event in events:\n",
    "                if event.is_final_response():\n",
    "                    llm_response = event.content.parts[0].text\n",
    "            \n",
    "            print(f\"âœ… [HYBRID] LLM routing complete!\")\n",
    "            print(f\"   Cost: ~$0.0002 | Stats: {self.stats['rule_count']} rule, {self.stats['llm_count']} LLM\")\n",
    "            \n",
    "            response_content = types.Content(\n",
    "                role='model',\n",
    "                parts=[types.Part(text=f\"[LLM-BASED ROUTING]\\n{llm_response}\")]\n",
    "            )\n",
    "        \n",
    "        # Create event\n",
    "        class SimpleEvent:\n",
    "            def __init__(self, content):\n",
    "                self.content = content\n",
    "                self.partial = False\n",
    "                self.timestamp = datetime.now(timezone.utc)\n",
    "                class SimpleActions:\n",
    "                    def __init__(self):\n",
    "                        self.state_delta = {}\n",
    "                self.actions = SimpleActions()\n",
    "            def is_final_response(self):\n",
    "                return True\n",
    "        \n",
    "        yield SimpleEvent(response_content)\n",
    "\n",
    "print(\"âœ… Hybrid Triage Agent class created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hybrid system\n",
    "hybrid_triage = HybridTriageAgent(\n",
    "    rule_agent=rule_triage,\n",
    "    llm_agent=llm_triage,\n",
    "    name=\"cost_optimized_triage\"\n",
    ")\n",
    "\n",
    "# Setup runner\n",
    "hybrid_session_service = InMemorySessionService()\n",
    "HYBRID_APP = \"hybrid_triage_app\"\n",
    "\n",
    "hybrid_runner = Runner(\n",
    "    app_name=HYBRID_APP,\n",
    "    agent=hybrid_triage,\n",
    "    session_service=hybrid_session_service\n",
    ")\n",
    "\n",
    "print(\"âœ… Hybrid System initialized!\")\n",
    "print(\"   Strategy: Try rules first, LLM fallback\")\n",
    "print(\"   Expected: 70% rule-based, 30% LLM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3: Test Hybrid System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper for testing hybrid system\n",
    "_hybrid_sessions = set()\n",
    "\n",
    "async def test_hybrid_routing_async(ticket: Dict, session_id: str = None):\n",
    "    \"\"\"Test hybrid routing.\"\"\"\n",
    "    if session_id is None:\n",
    "        session_id = f\"hybrid_session_{ticket['id']}\"\n",
    "    \n",
    "    user_id = \"hybrid_system\"\n",
    "    \n",
    "    session_key = (session_id, user_id)\n",
    "    if session_key not in _hybrid_sessions:\n",
    "        await hybrid_session_service.create_session(\n",
    "            app_name=HYBRID_APP,\n",
    "            user_id=user_id,\n",
    "            session_id=session_id,\n",
    "            state={}\n",
    "        )\n",
    "        _hybrid_sessions.add(session_key)\n",
    "    \n",
    "    content = types.Content(role='user', parts=[types.Part(text=ticket['description'])])\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ğŸ« TICKET {ticket['id']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Description: {ticket['description']}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    events = hybrid_runner.run_async(user_id=user_id, session_id=session_id, new_message=content)\n",
    "    \n",
    "    final_response = None\n",
    "    async for event in events:\n",
    "        if event.is_final_response():\n",
    "            final_response = event.content.parts[0].text\n",
    "    \n",
    "    elapsed_time = (time.time() - start_time) * 1000\n",
    "    \n",
    "    if final_response:\n",
    "        print(f\"\\nğŸ“Š ROUTING RESULT:\")\n",
    "        print(f\"{'-'*80}\")\n",
    "        print(final_response)\n",
    "        print(f\"{'-'*80}\")\n",
    "        print(f\"â±ï¸  Total time: {elapsed_time:.1f}ms\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return final_response\n",
    "\n",
    "def test_hybrid_routing(ticket: Dict, session_id: str = None):\n",
    "    \"\"\"Synchronous wrapper.\"\"\"\n",
    "    try:\n",
    "        loop = asyncio.get_running_loop()\n",
    "        import nest_asyncio\n",
    "        nest_asyncio.apply()\n",
    "        return asyncio.run(test_hybrid_routing_async(ticket, session_id))\n",
    "    except RuntimeError:\n",
    "        return asyncio.run(test_hybrid_routing_async(ticket, session_id))\n",
    "\n",
    "print(\"âœ… Hybrid test function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all tickets with hybrid system\n",
    "print(\"Testing all 8 tickets with hybrid triage...\\n\")\n",
    "\n",
    "for ticket in SAMPLE_TICKETS:\n",
    "    test_hybrid_routing(ticket)\n",
    "\n",
    "# Show final statistics\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"ğŸ“Š HYBRID SYSTEM PERFORMANCE\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Rule-based routings: {hybrid_triage.stats['rule_count']} ({hybrid_triage.stats['rule_count']/len(SAMPLE_TICKETS)*100:.0f}%)\")\n",
    "print(f\"LLM-based routings: {hybrid_triage.stats['llm_count']} ({hybrid_triage.stats['llm_count']/len(SAMPLE_TICKETS)*100:.0f}%)\")\n",
    "print(f\"\\nCost analysis (per ticket):\")\n",
    "print(f\"  Rule-based: $0.00\")\n",
    "print(f\"  LLM-based: ~$0.0002\")\n",
    "print(f\"  Average: ${(hybrid_triage.stats['llm_count']/len(SAMPLE_TICKETS))*0.0002:.6f}\")\n",
    "print(f\"\\nVs. all-LLM approach: ${len(SAMPLE_TICKETS)*0.0002:.4f}\")\n",
    "savings = (1 - (hybrid_triage.stats['llm_count']/len(SAMPLE_TICKETS))) * 100\n",
    "print(f\"Cost savings: {savings:.0f}%\")\n",
    "print(f\"{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4: Hybrid Architecture Key Observations\n",
    "\n",
    "**What you just saw:**\n",
    "\n",
    "1. âœ… **Intelligent routing**: Rules handle ~70%, LLM handles ~30%\n",
    "2. âœ… **Cost optimization**: Significant savings vs all-LLM approach\n",
    "3. âœ… **Speed optimization**: Rules are instant, LLM only when needed\n",
    "4. âœ… **Best of both worlds**: Determinism + Intelligence\n",
    "5. âœ… **Transparent metrics**: See exactly what's using LLM calls\n",
    "\n",
    "**Production Scaling:**\n",
    "\n",
    "For 10,000 daily tickets:\n",
    "- All-LLM: 10,000 Ã— $0.0002 = **$2.00/day** = $730/year\n",
    "- Hybrid (70/30): 3,000 Ã— $0.0002 = **$0.60/day** = $219/year\n",
    "- **Annual savings: $511 (70%)**\n",
    "\n",
    "At scale, this matters!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ Part 5: LoopAgent for Iterative Workflows\n",
    "\n",
    "### What is LoopAgent?\n",
    "\n",
    "LoopAgent repeats a workflow until:\n",
    "- Max iterations reached, OR\n",
    "- Break condition met\n",
    "\n",
    "### Use Case: Iterative Troubleshooting\n",
    "\n",
    "IT support often requires iteration:\n",
    "1. Try solution A\n",
    "2. Check if problem solved\n",
    "3. If not, try solution B\n",
    "4. Repeat until fixed or max attempts\n",
    "\n",
    "Let's build this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1: Create Troubleshooting Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent that suggests solutions\n",
    "solution_suggester = LlmAgent(\n",
    "    model=LiteLlm(model=f\"openai/{OPENAI_MODEL}\"),\n",
    "    name=\"solution_suggester\",\n",
    "    instruction=\"\"\"\n",
    "    You are an IT troubleshooting expert.\n",
    "    \n",
    "    Given a problem description, suggest ONE specific troubleshooting step.\n",
    "    Each iteration, suggest a different approach if previous didn't work.\n",
    "    \n",
    "    OUTPUT FORMAT:\n",
    "    STEP: [step number]\n",
    "    ACTION: [specific action to try]\n",
    "    EXPECTED RESULT: [what should happen if this works]\n",
    "    \n",
    "    Common progression:\n",
    "    1. Simple restart/reconnect\n",
    "    2. Check settings/configuration\n",
    "    3. Update drivers/software\n",
    "    4. Advanced troubleshooting\n",
    "    5. Escalate to specialist\n",
    "    \n",
    "    Be specific and actionable.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Agent that checks if problem is solved\n",
    "solution_checker = LlmAgent(\n",
    "    model=LiteLlm(model=f\"openai/{OPENAI_MODEL}\"),\n",
    "    name=\"solution_checker\",\n",
    "    instruction=\"\"\"\n",
    "    You are evaluating if a troubleshooting step resolved the issue.\n",
    "    \n",
    "    For this simulation, use logic:\n",
    "    - Step 1-2: Usually don't solve complex issues (continue)\n",
    "    - Step 3: Often solves the problem (can stop)\n",
    "    - Step 4+: Definitely solved or needs escalation\n",
    "    \n",
    "    OUTPUT FORMAT:\n",
    "    SOLVED: [yes/no]\n",
    "    REASONING: [why you think it's solved or not]\n",
    "    RECOMMENDATION: [stop/continue/escalate]\n",
    "    \n",
    "    If you output SOLVED: yes, the loop should terminate.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Troubleshooting agents created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2: Create LoopAgent with Termination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a loop agent for iterative troubleshooting\n",
    "# Note: LoopAgent continues until max_iterations or manual break\n",
    "\n",
    "troubleshooting_loop = LoopAgent(\n",
    "    name=\"troubleshooting_loop\",\n",
    "    sub_agents=[\n",
    "        solution_suggester,\n",
    "        solution_checker\n",
    "    ],\n",
    "    max_iterations=5  # Safety limit\n",
    ")\n",
    "\n",
    "print(\"âœ… LoopAgent created!\")\n",
    "print(f\"   Sub-agents: {len(troubleshooting_loop.sub_agents)}\")\n",
    "print(f\"   Max iterations: 5\")\n",
    "print(f\"   Strategy: Suggest â†’ Check â†’ Repeat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3: Test LoopAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup runner for loop agent\n",
    "loop_session_service = InMemorySessionService()\n",
    "LOOP_APP = \"loop_troubleshooting_app\"\n",
    "\n",
    "loop_runner = Runner(\n",
    "    app_name=LOOP_APP,\n",
    "    agent=troubleshooting_loop,\n",
    "    session_service=loop_session_service\n",
    ")\n",
    "\n",
    "print(\"âœ… LoopAgent runner initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the loop agent\n",
    "async def test_loop_troubleshooting_async(problem: str):\n",
    "    \"\"\"Test iterative troubleshooting.\"\"\"\n",
    "    session_id = \"loop_test_session\"\n",
    "    user_id = \"loop_user\"\n",
    "    \n",
    "    await loop_session_service.create_session(\n",
    "        app_name=LOOP_APP,\n",
    "        user_id=user_id,\n",
    "        session_id=session_id,\n",
    "        state={}\n",
    "    )\n",
    "    \n",
    "    content = types.Content(role='user', parts=[types.Part(text=problem)])\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ğŸ”„ ITERATIVE TROUBLESHOOTING\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Problem: {problem}\")\n",
    "    print(f\"\\nâ³ Starting iterative loop (max 5 iterations)...\\n\")\n",
    "    \n",
    "    events = loop_runner.run_async(user_id=user_id, session_id=session_id, new_message=content)\n",
    "    \n",
    "    iteration = 0\n",
    "    final_response = None\n",
    "    \n",
    "    async for event in events:\n",
    "        if event.is_final_response():\n",
    "            final_response = event.content.parts[0].text\n",
    "    \n",
    "    if final_response:\n",
    "        print(f\"\\nğŸ“Š TROUBLESHOOTING COMPLETE:\")\n",
    "        print(f\"{'-'*80}\")\n",
    "        print(final_response)\n",
    "        print(f\"{'-'*80}\")\n",
    "        print(f\"\\nâœ… Loop terminated\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return final_response\n",
    "\n",
    "def test_loop_troubleshooting(problem: str):\n",
    "    \"\"\"Synchronous wrapper.\"\"\"\n",
    "    try:\n",
    "        loop = asyncio.get_running_loop()\n",
    "        import nest_asyncio\n",
    "        nest_asyncio.apply()\n",
    "        return asyncio.run(test_loop_troubleshooting_async(problem))\n",
    "    except RuntimeError:\n",
    "        return asyncio.run(test_loop_troubleshooting_async(problem))\n",
    "\n",
    "print(\"âœ… Loop test function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a WiFi problem\n",
    "test_loop_troubleshooting(\"WiFi connection keeps dropping every few minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4: LoopAgent Key Observations\n",
    "\n",
    "**What you just saw:**\n",
    "\n",
    "1. âœ… **Iterative execution**: Agents run multiple times in sequence\n",
    "2. âœ… **Max iterations**: Safety mechanism prevents infinite loops\n",
    "3. âœ… **Stateful iteration**: Each iteration can build on previous\n",
    "4. âœ… **Termination conditions**: Can stop early if goal achieved\n",
    "5. âœ… **Real-world pattern**: Common in troubleshooting, optimization, refinement\n",
    "\n",
    "**When to Use LoopAgent:**\n",
    "- Iterative refinement (code review cycles, document editing)\n",
    "- Trial-and-error troubleshooting\n",
    "- Optimization problems (keep trying until good enough)\n",
    "- Multi-step verification (try, check, retry if needed)\n",
    "\n",
    "**Cost Consideration:**\n",
    "- Each iteration = 2 LLM calls (suggester + checker)\n",
    "- 5 iterations = 10 LLM calls total\n",
    "- Set max_iterations appropriately for your use case\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Part 6: Student Exercises\n",
    "\n",
    "### Exercise 1: Enhance Rule-Based Triage (Intermediate)\n",
    "\n",
    "**Task:** Add priority detection to the rule-based agent.\n",
    "\n",
    "**Requirements:**\n",
    "1. Detect urgency keywords: \"urgent\", \"asap\", \"critical\", \"emergency\"\n",
    "2. Assign priority: critical/high/medium/low\n",
    "3. Include priority in routing decision\n",
    "4. Still maintain $0 cost (no LLM calls)\n",
    "\n",
    "**Hint:** Add another rules dictionary for priority keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Your code here\n",
    "\n",
    "# TODO: Extend RuleBasedTriageAgent with priority detection\n",
    "# class EnhancedRuleBasedTriageAgent(BaseAgent):\n",
    "#     def __init__(self, name: str = \"enhanced_rule_triage\"):\n",
    "#         super().__init__(name=name)\n",
    "#         # Add priority rules\n",
    "#         self.priority_rules = {\n",
    "#             \"critical\": [\"urgent\", \"emergency\", ...],\n",
    "#             ...\n",
    "#         }\n",
    "#     ...\n",
    "\n",
    "# TODO: Test with tickets containing urgency keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Cost Analysis Tool (Beginner)\n",
    "\n",
    "**Task:** Create a function that calculates cost savings for different hybrid ratios.\n",
    "\n",
    "**Requirements:**\n",
    "1. Function takes: daily_tickets, rule_percentage\n",
    "2. Calculates: all-LLM cost vs hybrid cost\n",
    "3. Shows: daily, monthly, annual savings\n",
    "4. Compare: 50%, 70%, 90% rule coverage\n",
    "\n",
    "**Goal:** Understand the economics of hybrid architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Your code here\n",
    "\n",
    "def calculate_hybrid_savings(daily_tickets: int, rule_percentage: float):\n",
    "    \"\"\"\n",
    "    Calculate cost savings of hybrid vs all-LLM approach.\n",
    "    \n",
    "    Args:\n",
    "        daily_tickets: Number of tickets per day\n",
    "        rule_percentage: Percentage handled by rules (0.0 to 1.0)\n",
    "    \"\"\"\n",
    "    # TODO: Implement cost calculation\n",
    "    # LLM cost per request: $0.0002\n",
    "    # Rule cost per request: $0.00\n",
    "    pass\n",
    "\n",
    "# TODO: Test with different scenarios\n",
    "# calculate_hybrid_savings(10000, 0.70)\n",
    "# calculate_hybrid_savings(10000, 0.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Build Custom Loop Logic (Advanced)\n",
    "\n",
    "**Task:** Create a custom agent that implements retry logic manually.\n",
    "\n",
    "**Requirements:**\n",
    "1. Subclass BaseAgent\n",
    "2. Implement custom retry logic in _run_async_impl\n",
    "3. Try an action up to 3 times\n",
    "4. Track success/failure\n",
    "5. Stop on first success\n",
    "\n",
    "**Challenge:** Implement this without using LoopAgent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Your code here\n",
    "\n",
    "# class CustomRetryAgent(BaseAgent):\n",
    "#     def __init__(self, action_agent: LlmAgent, max_retries: int = 3, name: str = \"retry_agent\"):\n",
    "#         super().__init__(name=name, sub_agents=[action_agent])\n",
    "#         self.action_agent = action_agent\n",
    "#         self.max_retries = max_retries\n",
    "#     \n",
    "#     async def _run_async_impl(self, ctx: Any) -> AsyncGenerator[Any, None]:\n",
    "#         # TODO: Implement retry logic\n",
    "#         for attempt in range(self.max_retries):\n",
    "#             # Try action\n",
    "#             # Check if successful\n",
    "#             # If success, break\n",
    "#             # Otherwise, retry\n",
    "#         ...\n",
    "\n",
    "# TODO: Test the retry logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“‹ Part 7: Design Principles - Choosing the Right Approach\n",
    "\n",
    "### Decision Tree\n",
    "\n",
    "```\n",
    "Is the logic deterministic and rule-based?\n",
    "â”œâ”€ YES â†’ Use rule-based agent ($0, <10ms)\n",
    "â””â”€ NO â†’ Is it a simple decision?\n",
    "    â”œâ”€ YES â†’ Try hybrid (rules first, LLM fallback)\n",
    "    â””â”€ NO â†’ Is complex reasoning required?\n",
    "        â”œâ”€ YES â†’ Use LLM agent\n",
    "        â””â”€ NO â†’ Is iteration needed?\n",
    "            â”œâ”€ YES â†’ Use LoopAgent\n",
    "            â””â”€ NO â†’ Use appropriate workflow pattern\n",
    "```\n",
    "\n",
    "### Pattern Selection Matrix\n",
    "\n",
    "| Pattern | Cost | Speed | Use When | Example |\n",
    "|---------|------|-------|----------|--------|\n",
    "| **Rule-based** | $0 | <10ms | Clear keywords/thresholds | \"password\" â†’ security |\n",
    "| **Hybrid** | $0.0001 | 10-500ms | 70% simple, 30% complex | Try rules, fallback LLM |\n",
    "| **LLM** | $0.0002 | 500ms+ | Nuanced understanding | Complex reasoning |\n",
    "| **Sequential** | Nx cost | Nx time | Pipeline processing | Classify â†’ Prioritize â†’ Route |\n",
    "| **Parallel** | Nx cost | 1x time | Independent searches | Multi-source research |\n",
    "| **Loop** | Iteration Ã— cost | Iteration Ã— time | Trial-and-error | Troubleshooting steps |\n",
    "| **Hierarchical** | 1-2x cost | Variable | Complex triage | Route to specialist |\n",
    "\n",
    "### Cost Optimization Strategies\n",
    "\n",
    "**Layer 1: Rule-Based Filtering (70%)**\n",
    "- Handle obvious cases with keywords\n",
    "- Instant, free, deterministic\n",
    "- Example: FAQ matching, status checks\n",
    "\n",
    "**Layer 2: Hybrid Triage (20%)**\n",
    "- Rules couldn't decide confidently\n",
    "- Use cheap model (gpt-5-nano) for classification\n",
    "- Route to appropriate specialist\n",
    "\n",
    "**Layer 3: LLM Specialists (10%)**\n",
    "- Complex reasoning required\n",
    "- Use appropriate model for complexity\n",
    "- May use tools, multiple steps\n",
    "\n",
    "**Result: ~70-90% cost reduction vs all-LLM**\n",
    "\n",
    "### Production Best Practices\n",
    "\n",
    "1. **Start with rules**: Can you solve it without LLM?\n",
    "2. **Measure everything**: Track rule hit rate, LLM usage\n",
    "3. **Iterate on rules**: As patterns emerge, add more rules\n",
    "4. **Right-size models**: Don't use gpt-4o for simple tasks\n",
    "5. **Cache when possible**: Identical queries = cached responses\n",
    "6. **Set limits**: max_iterations, timeouts, fallbacks\n",
    "7. **Monitor costs**: Alert on unexpected LLM usage spikes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Part 8: Key Takeaways\n",
    "\n",
    "Congratulations! You've learned advanced production patterns!\n",
    "\n",
    "### What You Learned Today âœ…\n",
    "\n",
    "1. **Rule-Based Agents**\n",
    "   - Subclass BaseAgent for custom logic\n",
    "   - $0 cost, <10ms speed\n",
    "   - Perfect for deterministic decisions\n",
    "   - 100% consistent and debuggable\n",
    "\n",
    "2. **Hybrid Architectures**\n",
    "   - Combine rules + LLMs intelligently\n",
    "   - 70-90% cost reduction possible\n",
    "   - Rules handle simple, LLM handles complex\n",
    "   - Production best practice, not theory\n",
    "\n",
    "3. **LoopAgent Pattern**\n",
    "   - Iterative workflows with max_iterations\n",
    "   - Useful for troubleshooting, refinement\n",
    "   - Built-in safety mechanisms\n",
    "   - Stateful iteration support\n",
    "\n",
    "4. **Design Principles**\n",
    "   - \"Agent\" â‰  \"LLM\" always\n",
    "   - Right tool for the job\n",
    "   - Cost-awareness in design\n",
    "   - Measure and optimize\n",
    "\n",
    "### Production Architecture Example\n",
    "\n",
    "```\n",
    "                    User Request\n",
    "                         |\n",
    "                         â–¼\n",
    "                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                â”‚  Rule-Based     â”‚  70% handled\n",
    "                â”‚  Triage         â”‚  Cost: $0\n",
    "                â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                         â”‚\n",
    "                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                â”‚                 â”‚\n",
    "           Clear match       No match\n",
    "                â”‚                 â”‚\n",
    "                â–¼                 â–¼\n",
    "         Route to Team    LLM Triage  30% handled\n",
    "         Cost: $0         Cost: $0.0002\n",
    "                                  â”‚\n",
    "                                  â–¼\n",
    "                          Specialist Agent\n",
    "                          Cost: $0.0002-0.0010\n",
    "\n",
    "Result: 70% savings, same quality\n",
    "```\n",
    "\n",
    "### Real-World Impact\n",
    "\n",
    "**Startup (1,000 daily tickets):**\n",
    "- All-LLM: $73/year\n",
    "- Hybrid: $22/year\n",
    "- Savings: $51/year\n",
    "\n",
    "**Scale-up (10,000 daily tickets):**\n",
    "- All-LLM: $730/year\n",
    "- Hybrid: $219/year\n",
    "- Savings: $511/year\n",
    "\n",
    "**Enterprise (100,000 daily tickets):**\n",
    "- All-LLM: $7,300/year\n",
    "- Hybrid: $2,190/year\n",
    "- Savings: $5,110/year\n",
    "\n",
    "**At scale, architecture matters!**\n",
    "\n",
    "### Complete ADK Pattern Library ğŸ¨\n",
    "\n",
    "You now know:\n",
    "1. **Basic agents** (Lesson 1): LLM agents with personality\n",
    "2. **Tools** (Lesson 2): Function calling\n",
    "3. **Hierarchical routing** (Lesson 3): Coordinator + specialists\n",
    "4. **Sequential workflows** (Lesson 4): Pipeline processing\n",
    "5. **Parallel execution** (Lesson 4): Concurrent operations\n",
    "6. **Rule-based agents** (Lesson 5): Zero-cost deterministic logic\n",
    "7. **Hybrid systems** (Lesson 5): Cost-optimized architectures\n",
    "8. **Loop patterns** (Lesson 5): Iterative workflows\n",
    "\n",
    "### Next Steps ğŸš€\n",
    "\n",
    "You're ready to build production systems! Consider:\n",
    "- Persistent state (Firestore)\n",
    "- Error handling and retries\n",
    "- Monitoring and observability\n",
    "- MCP integration\n",
    "- Production deployment\n",
    "\n",
    "### Resources ğŸ“š\n",
    "\n",
    "- [ADK Custom Agents](https://google.github.io/adk-docs/agents/custom-agents/)\n",
    "- [ADK LoopAgent](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/)\n",
    "- [ADK Documentation](https://google.github.io/adk-docs/)\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“ Final Challenge\n",
    "\n",
    "Build a complete production IT support system that:\n",
    "1. Uses rule-based triage for 70%+ of tickets\n",
    "2. Falls back to LLM for complex cases\n",
    "3. Routes to appropriate specialist agents\n",
    "4. Implements retry logic for failed actions\n",
    "5. Tracks and reports cost metrics\n",
    "\n",
    "**You now have all the tools to build cost-effective, production-grade AI systems! ğŸ‰**\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
