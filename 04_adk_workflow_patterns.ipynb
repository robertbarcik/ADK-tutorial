{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqocKLz4M5oJ"
      },
      "source": [
        "# Lesson 4: Workflow Orchestration Patterns\n",
        "\n",
        "## üéØ Learning Objectives\n",
        "\n",
        "By the end of this lesson, you will be able to:\n",
        "\n",
        "1. **Understand** when to use workflow orchestration vs routing patterns\n",
        "2. **Implement** sequential workflows for multi-stage processes\n",
        "3. **Implement** parallel execution for concurrent information gathering\n",
        "4. **Compare** the performance and use cases of each pattern\n",
        "5. **Apply** workflow patterns to real-world production scenarios\n",
        "6. **Optimize** workflows for cost and performance\n",
        "\n",
        "## üìö Quick Recap: Lessons 1-3\n",
        "\n",
        "In previous lessons, you learned:\n",
        "- ‚úÖ How to create agents with tools (function calling)\n",
        "- ‚úÖ How to build hierarchical routing with coordinator + specialists\n",
        "- ‚úÖ How agents transfer control using `sub_agents` and `transfer_to_agent()`\n",
        "\n",
        "**New in this lesson**: Instead of intelligent routing, we'll use **deterministic workflow patterns** where execution order is fixed and predictable.\n",
        "\n",
        "## üöÄ What's New: Workflow Agents\n",
        "\n",
        "ADK provides two powerful workflow orchestration patterns:\n",
        "\n",
        "- üìã **SequentialAgent**: Execute agents in strict order (A ‚Üí B ‚Üí C)\n",
        "- ‚ö° **ParallelAgent**: Execute agents concurrently (A + B + C simultaneously)\n",
        "\n",
        "**Key difference from Lesson 3**: These are NOT LLM-powered. They follow predetermined, **deterministic** execution patterns.\n",
        "\n",
        "## üè¢ Use Case: IT Support Automation\n",
        "\n",
        "We'll build two workflow systems:\n",
        "1. **Sequential**: Automated ticket processing pipeline\n",
        "2. **Parallel**: Multi-source information gathering\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYIW8GhXM5oL"
      },
      "source": [
        "## üí° Part 1: Understanding Workflow Patterns\n",
        "\n",
        "### When to Use Each Pattern\n",
        "\n",
        "| Pattern | Use When | Example |\n",
        "|---------|----------|----------|\n",
        "| **Hierarchical Routing** (Lesson 3) | Request needs ONE specialist | Route \"Wi-Fi issue\" ‚Üí Network Specialist |\n",
        "| **Sequential Workflow** (This lesson) | Task needs MULTIPLE steps in order | Process ticket: Classify ‚Üí Prioritize ‚Üí Assign |\n",
        "| **Parallel Execution** (This lesson) | Need info from MULTIPLE sources | Search: KB + Tickets + Docs simultaneously |\n",
        "\n",
        "### Sequential vs Parallel Comparison\n",
        "\n",
        "```\n",
        "SEQUENTIAL WORKFLOW:           PARALLEL EXECUTION:\n",
        "Agent A                        Agent A ‚îê\n",
        "   ‚Üì                                   ‚îú‚îÄ‚Üí Aggregate Results\n",
        "Agent B                        Agent B ‚î§\n",
        "   ‚Üì                                   ‚îú‚îÄ‚Üí Aggregate Results  \n",
        "Agent C                        Agent C ‚îò\n",
        "   ‚Üì\n",
        "Result                         Result\n",
        "\n",
        "Time: 3x                       Time: 1x (3x parallel)\n",
        "When: Steps depend on each     When: Steps are independent\n",
        "      other                          \n",
        "```\n",
        "\n",
        "### Real-World Examples\n",
        "\n",
        "**Sequential Workflows:**\n",
        "- üìù Document pipeline: Write ‚Üí Review ‚Üí Publish\n",
        "- üéØ Sales process: Qualify ‚Üí Demo ‚Üí Quote ‚Üí Close\n",
        "- üè≠ Manufacturing: Design ‚Üí Build ‚Üí Test ‚Üí Ship\n",
        "- üéì Course creation: Research ‚Üí Write ‚Üí Edit ‚Üí Publish\n",
        "\n",
        "**Parallel Execution:**\n",
        "- üîç Research: Search multiple databases at once\n",
        "- üåê API aggregation: Call multiple APIs simultaneously\n",
        "- üìä Data analysis: Analyze different datasets in parallel\n",
        "- üîê Validation: Check multiple conditions concurrently\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inYoLj96M5oM"
      },
      "source": [
        "## üîß Part 2: Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZqOEZCVM5oM"
      },
      "outputs": [],
      "source": [
        "# Install the Google Agent Development Kit and dependencies\n",
        "!pip install -q google-adk litellm openai python-dotenv nest-asyncio\n",
        "\n",
        "print(\"‚úÖ Packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OKiEX2aM5oN"
      },
      "outputs": [],
      "source": [
        "# Core ADK imports - including workflow agents!\n",
        "from google.adk.agents import LlmAgent, SequentialAgent, ParallelAgent\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.models.lite_llm import LiteLlm\n",
        "from google.genai import types\n",
        "\n",
        "# System imports\n",
        "import os\n",
        "import asyncio\n",
        "import time\n",
        "from typing import Dict, List, Any\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"‚úÖ Imports successful!\")\n",
        "print(\"   Workflow agents imported: SequentialAgent, ParallelAgent\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rs8rC83FM5oN"
      },
      "outputs": [],
      "source": [
        "# Configure OpenAI API key\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "    print(\"‚úÖ API key loaded from Colab secrets\")\n",
        "except:\n",
        "    from getpass import getpass\n",
        "    print(\"üí° To use Colab secrets: Go to üîë (left sidebar) ‚Üí Add new secret ‚Üí Name: OPENAI_API_KEY\")\n",
        "    OPENAI_API_KEY = getpass(\"Enter your OpenAI API Key: \")\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "\n",
        "if not OPENAI_API_KEY or OPENAI_API_KEY.strip() == \"\":\n",
        "    raise ValueError(\"‚ùå ERROR: No API key provided!\")\n",
        "\n",
        "print(\"‚úÖ Authentication configured!\")\n",
        "\n",
        "# Model configuration\n",
        "OPENAI_MODEL = \"gpt-5-nano\"  # Cost-efficient for learning\n",
        "\n",
        "print(f\"\\nü§ñ Model: {OPENAI_MODEL}\")\n",
        "print(\"\\nüí° Workflow agents are model-agnostic!\")\n",
        "print(\"   Same code works with any LLM provider:\")\n",
        "print(\"   - OpenAI: 'gpt-5-nano', 'gpt-4o-mini', 'gpt-4o'\")\n",
        "print(\"   - Claude: 'claude-3-5-sonnet-20241022'\")\n",
        "print(\"   - Gemini: 'gemini-2.0-flash-exp'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJsG_ea2M5oO"
      },
      "source": [
        "---\n",
        "\n",
        "## üìã Part 3: Pattern A - Sequential Workflows\n",
        "\n",
        "### Use Case: Automated Ticket Processing Pipeline\n",
        "\n",
        "When a new IT support ticket arrives, it needs to go through multiple stages:\n",
        "1. **Classify** the issue type (hardware, software, network)\n",
        "2. **Prioritize** based on urgency and impact\n",
        "3. **Assign** to the appropriate team\n",
        "\n",
        "These steps MUST happen in order:\n",
        "- Can't prioritize before classifying\n",
        "- Can't assign before knowing priority\n",
        "\n",
        "### How SequentialAgent Works\n",
        "\n",
        "```python\n",
        "pipeline = SequentialAgent(\n",
        "    name=\"ticket_pipeline\",\n",
        "    sub_agents=[agent1, agent2, agent3]  # Execute in this exact order\n",
        ")\n",
        "```\n",
        "\n",
        "- ‚úÖ Agents execute in the order specified\n",
        "- ‚úÖ Each agent sees output from previous agents\n",
        "- ‚úÖ Shared session state passes data between stages\n",
        "- ‚úÖ Deterministic - no LLM decides the flow\n",
        "\n",
        "Let's build it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BTNXd6GM5oO"
      },
      "source": [
        "### 3.1: Create Mock Ticket Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wrKBj6FM5oO"
      },
      "outputs": [],
      "source": [
        "# Sample tickets for testing the pipeline\n",
        "SAMPLE_TICKETS = [\n",
        "    {\n",
        "        \"ticket_id\": \"T-5001\",\n",
        "        \"description\": \"My laptop won't turn on after I spilled coffee on it. It's completely dead and I have a presentation in 2 hours!\",\n",
        "        \"user\": \"john.doe@company.com\",\n",
        "        \"submitted_at\": \"2025-10-06 08:30:00\"\n",
        "    },\n",
        "    {\n",
        "        \"ticket_id\": \"T-5002\",\n",
        "        \"description\": \"I can't access my email. It says my password is incorrect but I'm sure it's right.\",\n",
        "        \"user\": \"jane.smith@company.com\",\n",
        "        \"submitted_at\": \"2025-10-06 09:15:00\"\n",
        "    },\n",
        "    {\n",
        "        \"ticket_id\": \"T-5003\",\n",
        "        \"description\": \"The Wi-Fi in our conference room is really slow during meetings.\",\n",
        "        \"user\": \"bob.wilson@company.com\",\n",
        "        \"submitted_at\": \"2025-10-06 10:00:00\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"‚úÖ Sample tickets loaded!\")\n",
        "print(f\"   Total tickets: {len(SAMPLE_TICKETS)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y89hEnJeM5oO"
      },
      "source": [
        "### 3.2: Stage 1 - Ticket Classifier Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLFzaQfWM5oO"
      },
      "outputs": [],
      "source": [
        "# Stage 1: Classify the ticket type\n",
        "ticket_classifier = LlmAgent(\n",
        "    model=LiteLlm(model=f\"openai/{OPENAI_MODEL}\"),\n",
        "    name=\"ticket_classifier\",\n",
        "    instruction=\"\"\"\n",
        "    You are a Ticket Classifier in an IT support automation pipeline.\n",
        "\n",
        "    YOUR TASK:\n",
        "    Analyze the ticket description and classify it into ONE category:\n",
        "    - hardware: Physical device issues (laptop, printer, monitor)\n",
        "    - software: Application or license issues\n",
        "    - network: Connectivity or internet issues\n",
        "    - access: Account, password, or permissions issues\n",
        "\n",
        "    OUTPUT FORMAT:\n",
        "    You must respond with EXACTLY this format:\n",
        "    CATEGORY: [category]\n",
        "    REASONING: [brief explanation]\n",
        "\n",
        "    Example:\n",
        "    CATEGORY: hardware\n",
        "    REASONING: User reports physical damage to laptop (coffee spill)\n",
        "\n",
        "    Be concise and accurate. This classification determines the next steps.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Ticket Classifier created!\")\n",
        "print(f\"   Model: {OPENAI_MODEL}\")\n",
        "print(f\"   Role: Stage 1 - Classify ticket type\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkGNd74SM5oO"
      },
      "source": [
        "### 3.3: Stage 2 - Priority Assigner Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaRkqEbcM5oO"
      },
      "outputs": [],
      "source": [
        "# Stage 2: Assign priority level\n",
        "priority_assigner = LlmAgent(\n",
        "    model=LiteLlm(model=f\"openai/{OPENAI_MODEL}\"),\n",
        "    name=\"priority_assigner\",\n",
        "    instruction=\"\"\"\n",
        "    You are a Priority Assigner in an IT support automation pipeline.\n",
        "\n",
        "    YOUR TASK:\n",
        "    Based on the ticket description and classification, assign a priority level:\n",
        "    - critical: System down, data loss, blocking work for multiple people\n",
        "    - high: Blocking individual user's work, urgent deadline\n",
        "    - medium: Impacting work but has workarounds\n",
        "    - low: Minor inconvenience, no immediate impact\n",
        "\n",
        "    PRIORITY FACTORS:\n",
        "    - Impact: How many people affected?\n",
        "    - Urgency: Time-sensitive? Deadline mentioned?\n",
        "    - Severity: How broken is it? Complete failure vs slow performance?\n",
        "\n",
        "    OUTPUT FORMAT:\n",
        "    PRIORITY: [critical/high/medium/low]\n",
        "    REASONING: [explain why this priority]\n",
        "    SLA: [response time - e.g., \"15 minutes\", \"2 hours\", \"24 hours\"]\n",
        "\n",
        "    Be decisive. Consider urgency keywords like \"urgent\", \"ASAP\", time mentions.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Priority Assigner created!\")\n",
        "print(f\"   Model: {OPENAI_MODEL}\")\n",
        "print(f\"   Role: Stage 2 - Assign priority level\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVUx7fyVM5oO"
      },
      "source": [
        "### 3.4: Stage 3 - Team Assigner Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDa5CUvIM5oO"
      },
      "outputs": [],
      "source": [
        "# Stage 3: Assign to appropriate team\n",
        "team_assigner = LlmAgent(\n",
        "    model=LiteLlm(model=f\"openai/{OPENAI_MODEL}\"),\n",
        "    name=\"team_assigner\",\n",
        "    instruction=\"\"\"\n",
        "    You are a Team Assigner in an IT support automation pipeline.\n",
        "\n",
        "    YOUR TASK:\n",
        "    Based on the ticket category and priority, assign it to the correct team:\n",
        "\n",
        "    TEAMS:\n",
        "    - hardware_team: Physical device repairs and replacements\n",
        "    - software_team: Application issues, licenses, installations\n",
        "    - network_team: Connectivity, internet, VPN issues\n",
        "    - security_team: Access control, passwords, permissions\n",
        "\n",
        "    ESCALATION RULES:\n",
        "    - Critical priority: Assign to senior member\n",
        "    - High priority: Regular team member\n",
        "    - Medium/Low: Junior team member or queue\n",
        "\n",
        "    OUTPUT FORMAT:\n",
        "    TEAM: [team_name]\n",
        "    ASSIGNEE: [senior/regular/junior/queue]\n",
        "    NEXT_ACTION: [what the team should do first]\n",
        "\n",
        "    Make logical assignments based on category and urgency.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Team Assigner created!\")\n",
        "print(f\"   Model: {OPENAI_MODEL}\")\n",
        "print(f\"   Role: Stage 3 - Assign to team\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twmImXGyM5oP"
      },
      "source": [
        "### 3.5: Create the Sequential Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9bkJtWZM5oP"
      },
      "outputs": [],
      "source": [
        "# Create the sequential ticket processing pipeline\n",
        "ticket_pipeline = SequentialAgent(\n",
        "    name=\"ticket_processing_pipeline\",\n",
        "    sub_agents=[\n",
        "        ticket_classifier,    # Stage 1: Classify\n",
        "        priority_assigner,    # Stage 2: Prioritize\n",
        "        team_assigner        # Stage 3: Assign\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Sequential Pipeline created!\")\n",
        "print(f\"\\nüìã Pipeline stages:\")\n",
        "print(f\"   1. {ticket_classifier.name} ‚Üí Classify ticket type\")\n",
        "print(f\"   2. {priority_assigner.name} ‚Üí Assign priority level\")\n",
        "print(f\"   3. {team_assigner.name} ‚Üí Route to team\")\n",
        "print(f\"\\n‚ö° Execution: Sequential (one after another)\")\n",
        "print(f\"   Each stage sees the output from previous stages\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_GawWbsM5oP"
      },
      "source": [
        "### 3.6: Setup Runner for Sequential Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mENPk5YeM5oP"
      },
      "outputs": [],
      "source": [
        "# Create session service and runner\n",
        "session_service = InMemorySessionService()\n",
        "APP_NAME = \"ticket_pipeline_app\"\n",
        "\n",
        "pipeline_runner = Runner(\n",
        "    app_name=APP_NAME,\n",
        "    agent=ticket_pipeline,\n",
        "    session_service=session_service\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Pipeline Runner initialized!\")\n",
        "print(f\"   App: {APP_NAME}\")\n",
        "print(f\"   Root Agent: {ticket_pipeline.name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WKbRf0rM5oP"
      },
      "source": [
        "### 3.7: Test the Sequential Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCcvFyZgM5oP"
      },
      "outputs": [],
      "source": [
        "# Helper function to process a ticket through the pipeline\n",
        "_created_sessions = set()\n",
        "\n",
        "async def process_ticket_async(ticket: Dict, session_id: str = None):\n",
        "    \"\"\"\n",
        "    Process a ticket through the sequential pipeline.\n",
        "    \"\"\"\n",
        "    if session_id is None:\n",
        "        session_id = f\"session_{ticket['ticket_id']}\"\n",
        "\n",
        "    user_id = \"pipeline_system\"\n",
        "\n",
        "    # Create session\n",
        "    session_key = (session_id, user_id)\n",
        "    if session_key not in _created_sessions:\n",
        "        await session_service.create_session(\n",
        "            app_name=APP_NAME,\n",
        "            user_id=user_id,\n",
        "            session_id=session_id,\n",
        "            state={}\n",
        "        )\n",
        "        _created_sessions.add(session_key)\n",
        "\n",
        "    # Format ticket as input message\n",
        "    ticket_message = f\"\"\"\n",
        "    Ticket ID: {ticket['ticket_id']}\n",
        "    User: {ticket['user']}\n",
        "    Submitted: {ticket['submitted_at']}\n",
        "    Description: {ticket['description']}\n",
        "    \"\"\"\n",
        "\n",
        "    content = types.Content(role='user', parts=[types.Part(text=ticket_message)])\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"üé´ PROCESSING TICKET: {ticket['ticket_id']}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"Description: {ticket['description'][:100]}...\")\n",
        "    print(f\"\\n‚è≥ Starting sequential pipeline...\\n\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Run pipeline\n",
        "    events = pipeline_runner.run_async(user_id=user_id, session_id=session_id, new_message=content)\n",
        "\n",
        "    stage_outputs = []\n",
        "    final_response = None\n",
        "\n",
        "    async for event in events:\n",
        "        if event.is_final_response():\n",
        "            final_response = event.content.parts[0].text\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    if final_response:\n",
        "        print(f\"\\nüìä PIPELINE RESULTS:\")\n",
        "        print(f\"{'-'*80}\")\n",
        "        print(final_response)\n",
        "        print(f\"{'-'*80}\")\n",
        "        print(f\"\\n‚è±Ô∏è  Processing time: {elapsed_time:.2f} seconds\")\n",
        "        print(f\"‚úÖ Ticket {ticket['ticket_id']} processed successfully!\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "\n",
        "    return final_response\n",
        "\n",
        "def process_ticket(ticket: Dict, session_id: str = None):\n",
        "    \"\"\"Synchronous wrapper for process_ticket_async.\"\"\"\n",
        "    try:\n",
        "        loop = asyncio.get_running_loop()\n",
        "        import nest_asyncio\n",
        "        nest_asyncio.apply()\n",
        "        return asyncio.run(process_ticket_async(ticket, session_id))\n",
        "    except RuntimeError:\n",
        "        return asyncio.run(process_ticket_async(ticket, session_id))\n",
        "\n",
        "print(\"‚úÖ Pipeline test function ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJtiHy3bM5oP"
      },
      "source": [
        "### 3.8: Run Pipeline Demonstrations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6o2fIPIdM5oP"
      },
      "outputs": [],
      "source": [
        "# Demo 1: Critical hardware issue\n",
        "process_ticket(SAMPLE_TICKETS[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iyZdVvgM5oQ"
      },
      "outputs": [],
      "source": [
        "# Demo 2: Access/password issue\n",
        "process_ticket(SAMPLE_TICKETS[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZzm5CWSM5oQ"
      },
      "outputs": [],
      "source": [
        "# Demo 3: Network performance issue\n",
        "process_ticket(SAMPLE_TICKETS[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2zg65FAM5oQ"
      },
      "source": [
        "### 3.9: Sequential Pipeline Key Observations\n",
        "\n",
        "**What you just saw:**\n",
        "\n",
        "1. ‚úÖ **Strict order**: Classifier ‚Üí Priority ‚Üí Team (always this sequence)\n",
        "2. ‚úÖ **Data flow**: Each stage sees results from previous stages\n",
        "3. ‚úÖ **Deterministic**: No LLM decides the flow, it's hardcoded\n",
        "4. ‚úÖ **Cumulative time**: Total time = sum of all stages\n",
        "\n",
        "**When Sequential is Perfect:**\n",
        "- Steps depend on previous results\n",
        "- Order matters for correctness\n",
        "- Need predictable execution flow\n",
        "- Building assembly line / pipeline processes\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB3jJhraM5oQ"
      },
      "source": [
        "## ‚ö° Part 4: Pattern B - Parallel Execution\n",
        "\n",
        "### Use Case: Multi-Source Information Gathering\n",
        "\n",
        "When researching how to solve a ticket, we want to search multiple sources:\n",
        "1. **Internal knowledge base** - Published solutions\n",
        "2. **Past resolved tickets** - Similar issues solved before\n",
        "3. **System documentation** - Technical specs and configs\n",
        "\n",
        "These searches are INDEPENDENT:\n",
        "- Each search doesn't depend on others\n",
        "- They can all run at the same time\n",
        "- Results are aggregated afterwards\n",
        "\n",
        "### How ParallelAgent Works\n",
        "\n",
        "```python\n",
        "parallel_research = ParallelAgent(\n",
        "    name=\"parallel_researcher\",\n",
        "    sub_agents=[agent1, agent2, agent3]  # Execute simultaneously\n",
        ")\n",
        "```\n",
        "\n",
        "- ‚úÖ All agents execute at the same time\n",
        "- ‚úÖ Dramatically faster than sequential\n",
        "- ‚úÖ Each agent works independently\n",
        "- ‚úÖ Results are collected and returned together\n",
        "\n",
        "Let's build it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbJij4IPM5oQ"
      },
      "source": [
        "### 4.1: Create Mock Data Sources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwFr-jJ8M5oQ"
      },
      "outputs": [],
      "source": [
        "# Mock knowledge base database\n",
        "KNOWLEDGE_BASE = [\n",
        "    {\"id\": \"KB-001\", \"title\": \"Wi-Fi Connection Issues\", \"solution\": \"Reset router, check DNS settings, update drivers\"},\n",
        "    {\"id\": \"KB-002\", \"title\": \"Password Reset Procedures\", \"solution\": \"Use self-service portal, verify with 2FA, contact security team\"},\n",
        "    {\"id\": \"KB-003\", \"title\": \"Laptop Won't Boot\", \"solution\": \"Check power supply, test with external display, run diagnostics\"},\n",
        "    {\"id\": \"KB-004\", \"title\": \"Email Access Problems\", \"solution\": \"Clear browser cache, try different browser, reset password\"},\n",
        "    {\"id\": \"KB-005\", \"title\": \"Slow Network Performance\", \"solution\": \"Check bandwidth, test different location, verify router settings\"},\n",
        "]\n",
        "\n",
        "# Mock resolved tickets database\n",
        "RESOLVED_TICKETS = [\n",
        "    {\"id\": \"T-4501\", \"issue\": \"Laptop power failure\", \"resolution\": \"Replaced battery, tested charging port\", \"time\": \"2 hours\"},\n",
        "    {\"id\": \"T-4502\", \"issue\": \"Email login failure\", \"resolution\": \"Reset password via self-service portal\", \"time\": \"15 minutes\"},\n",
        "    {\"id\": \"T-4503\", \"issue\": \"Conference room Wi-Fi slow\", \"resolution\": \"Upgraded router firmware, optimized channel\", \"time\": \"3 hours\"},\n",
        "    {\"id\": \"T-4504\", \"issue\": \"Cannot access VPN\", \"resolution\": \"Renewed VPN certificate, updated client\", \"time\": \"1 hour\"},\n",
        "]\n",
        "\n",
        "# Mock system documentation\n",
        "SYSTEM_DOCS = [\n",
        "    {\"system\": \"Email Server\", \"version\": \"Exchange 2019\", \"config\": \"AD authentication, 2FA enabled\"},\n",
        "    {\"system\": \"Network Infrastructure\", \"version\": \"Cisco Catalyst\", \"config\": \"VLAN segmentation, 802.11ac\"},\n",
        "    {\"system\": \"Laptop Standard Build\", \"version\": \"Windows 11 Pro\", \"config\": \"Dell Latitude 5520, 16GB RAM\"},\n",
        "    {\"system\": \"VPN Gateway\", \"version\": \"Cisco AnyConnect\", \"config\": \"Split tunneling enabled\"},\n",
        "]\n",
        "\n",
        "print(\"‚úÖ Mock data sources loaded!\")\n",
        "print(f\"   Knowledge Base: {len(KNOWLEDGE_BASE)} articles\")\n",
        "print(f\"   Resolved Tickets: {len(RESOLVED_TICKETS)} tickets\")\n",
        "print(f\"   System Docs: {len(SYSTEM_DOCS)} systems\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlBa4FMUM5oQ"
      },
      "source": [
        "### 4.2: Agent 1 - Knowledge Base Searcher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DERVBpglM5oQ"
      },
      "outputs": [],
      "source": [
        "# Agent 1: Search knowledge base\n",
        "kb_searcher = LlmAgent(\n",
        "    model=LiteLlm(model=f\"openai/{OPENAI_MODEL}\"),\n",
        "    name=\"kb_searcher\",\n",
        "    instruction=f\"\"\"\n",
        "    You are a Knowledge Base Searcher in a parallel research system.\n",
        "\n",
        "    YOUR TASK:\n",
        "    Search the knowledge base for relevant articles that could help solve the issue.\n",
        "\n",
        "    AVAILABLE KNOWLEDGE BASE:\n",
        "    {KNOWLEDGE_BASE}\n",
        "\n",
        "    OUTPUT FORMAT:\n",
        "    SOURCE: Knowledge Base\n",
        "    RELEVANT ARTICLES: [list article IDs and titles]\n",
        "    RECOMMENDED SOLUTION: [summarize the most relevant solution]\n",
        "    CONFIDENCE: [high/medium/low]\n",
        "\n",
        "    Focus on finding the most relevant articles for the issue described.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Knowledge Base Searcher created!\")\n",
        "print(f\"   Model: {OPENAI_MODEL}\")\n",
        "print(f\"   Role: Search internal KB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65eNZs2bM5oQ"
      },
      "source": [
        "### 4.3: Agent 2 - Ticket History Searcher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6xCn0ymM5oQ"
      },
      "outputs": [],
      "source": [
        "# Agent 2: Search resolved tickets\n",
        "ticket_searcher = LlmAgent(\n",
        "    model=LiteLlm(model=f\"openai/{OPENAI_MODEL}\"),\n",
        "    name=\"ticket_searcher\",\n",
        "    instruction=f\"\"\"\n",
        "    You are a Ticket History Searcher in a parallel research system.\n",
        "\n",
        "    YOUR TASK:\n",
        "    Search past resolved tickets for similar issues and their solutions.\n",
        "\n",
        "    AVAILABLE RESOLVED TICKETS:\n",
        "    {RESOLVED_TICKETS}\n",
        "\n",
        "    OUTPUT FORMAT:\n",
        "    SOURCE: Resolved Tickets\n",
        "    SIMILAR TICKETS: [list ticket IDs and issues]\n",
        "    PROVEN SOLUTIONS: [what worked in the past]\n",
        "    RESOLUTION TIME: [typical time to resolve]\n",
        "\n",
        "    Focus on tickets with similar symptoms and successful resolutions.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Ticket History Searcher created!\")\n",
        "print(f\"   Model: {OPENAI_MODEL}\")\n",
        "print(f\"   Role: Search past tickets\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_EOiQmFM5oQ"
      },
      "source": [
        "### 4.4: Agent 3 - Documentation Searcher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydBvl1ORM5oQ"
      },
      "outputs": [],
      "source": [
        "# Agent 3: Search system documentation\n",
        "docs_searcher = LlmAgent(\n",
        "    model=LiteLlm(model=f\"openai/{OPENAI_MODEL}\"),\n",
        "    name=\"docs_searcher\",\n",
        "    instruction=f\"\"\"\n",
        "    You are a System Documentation Searcher in a parallel research system.\n",
        "\n",
        "    YOUR TASK:\n",
        "    Search system documentation for relevant configurations and technical details.\n",
        "\n",
        "    AVAILABLE SYSTEM DOCUMENTATION:\n",
        "    {SYSTEM_DOCS}\n",
        "\n",
        "    OUTPUT FORMAT:\n",
        "    SOURCE: System Documentation\n",
        "    RELEVANT SYSTEMS: [list system names]\n",
        "    TECHNICAL DETAILS: [configuration info that might help]\n",
        "    CONSIDERATIONS: [any technical constraints or requirements]\n",
        "\n",
        "    Focus on technical specifications that could be relevant to troubleshooting.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Documentation Searcher created!\")\n",
        "print(f\"   Model: {OPENAI_MODEL}\")\n",
        "print(f\"   Role: Search system docs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRuGKG9bM5oR"
      },
      "source": [
        "### 4.5: Create the Parallel Research Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOlv0jR4M5oR"
      },
      "outputs": [],
      "source": [
        "# Create the parallel information gathering system\n",
        "parallel_researcher = ParallelAgent(\n",
        "    name=\"parallel_information_gatherer\",\n",
        "    sub_agents=[\n",
        "        kb_searcher,        # Search KB simultaneously\n",
        "        ticket_searcher,    # Search tickets simultaneously\n",
        "        docs_searcher      # Search docs simultaneously\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Parallel Research Agent created!\")\n",
        "print(f\"\\n‚ö° Research sources (running in parallel):\")\n",
        "print(f\"   1. {kb_searcher.name} ‚Üí Search knowledge base\")\n",
        "print(f\"   2. {ticket_searcher.name} ‚Üí Search past tickets\")\n",
        "print(f\"   3. {docs_searcher.name} ‚Üí Search system docs\")\n",
        "print(f\"\\n‚ö° Execution: Parallel (all at once)\")\n",
        "print(f\"   ~3x faster than sequential search!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmrHVAlZM5oR"
      },
      "source": [
        "### 4.6: Setup Runner for Parallel Research"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyR6nSIiM5oR"
      },
      "outputs": [],
      "source": [
        "# Create separate app for parallel research\n",
        "RESEARCH_APP_NAME = \"parallel_research_app\"\n",
        "research_session_service = InMemorySessionService()\n",
        "\n",
        "research_runner = Runner(\n",
        "    app_name=RESEARCH_APP_NAME,\n",
        "    agent=parallel_researcher,\n",
        "    session_service=research_session_service\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Parallel Research Runner initialized!\")\n",
        "print(f\"   App: {RESEARCH_APP_NAME}\")\n",
        "print(f\"   Root Agent: {parallel_researcher.name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e6L15g8M5oR"
      },
      "source": [
        "### 4.7: Test Parallel Research"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGZjybJIM5oR"
      },
      "outputs": [],
      "source": [
        "# Helper function for parallel research\n",
        "_research_sessions = set()\n",
        "\n",
        "async def research_issue_async(issue_description: str, session_id: str = \"research_001\"):\n",
        "    \"\"\"\n",
        "    Research an issue using parallel information gathering.\n",
        "    Shows individual agent responses for educational purposes.\n",
        "    \"\"\"\n",
        "    user_id = \"research_system\"\n",
        "\n",
        "    # Create session\n",
        "    session_key = (session_id, user_id)\n",
        "    if session_key not in _research_sessions:\n",
        "        await research_session_service.create_session(\n",
        "            app_name=RESEARCH_APP_NAME,\n",
        "            user_id=user_id,\n",
        "            session_id=session_id,\n",
        "            state={}\n",
        "        )\n",
        "        _research_sessions.add(session_key)\n",
        "\n",
        "    content = types.Content(role='user', parts=[types.Part(text=issue_description)])\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"üîç PARALLEL RESEARCH QUERY\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"Issue: {issue_description}\")\n",
        "    print(f\"\\n‚ö° Launching 3 parallel agents...\\n\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # For educational purposes, let's also run individual agents separately to show their outputs\n",
        "    # This demonstrates what each agent finds before aggregation\n",
        "    print(f\"{'‚îÄ'*80}\")\n",
        "    print(f\"üî¨ INDIVIDUAL AGENT RESPONSES:\")\n",
        "    print(f\"{'‚îÄ'*80}\\n\")\n",
        "\n",
        "    # Run each searcher individually to show what they find\n",
        "    individual_results = []\n",
        "\n",
        "    # KB Searcher\n",
        "    print(f\"üìö KB SEARCHER:\")\n",
        "    print(f\"{'-'*80}\")\n",
        "    kb_session_id = f\"{session_id}_kb\"\n",
        "    kb_session_service = InMemorySessionService()\n",
        "    await kb_session_service.create_session(\n",
        "        app_name=\"kb_search\",\n",
        "        user_id=user_id,\n",
        "        session_id=kb_session_id,\n",
        "        state={}\n",
        "    )\n",
        "    kb_runner = Runner(app_name=\"kb_search\", agent=kb_searcher, session_service=kb_session_service)\n",
        "    events = kb_runner.run_async(user_id=user_id, session_id=kb_session_id, new_message=content)\n",
        "    async for event in events:\n",
        "        if event.is_final_response():\n",
        "            kb_result = event.content.parts[0].text\n",
        "            print(kb_result)\n",
        "            individual_results.append((\"KB Searcher\", kb_result))\n",
        "    print(f\"{'-'*80}\\n\")\n",
        "\n",
        "    # Ticket Searcher\n",
        "    print(f\"üé´ TICKET SEARCHER:\")\n",
        "    print(f\"{'-'*80}\")\n",
        "    ticket_session_id = f\"{session_id}_ticket\"\n",
        "    ticket_session_service = InMemorySessionService()\n",
        "    await ticket_session_service.create_session(\n",
        "        app_name=\"ticket_search\",\n",
        "        user_id=user_id,\n",
        "        session_id=ticket_session_id,\n",
        "        state={}\n",
        "    )\n",
        "    ticket_runner = Runner(app_name=\"ticket_search\", agent=ticket_searcher, session_service=ticket_session_service)\n",
        "    events = ticket_runner.run_async(user_id=user_id, session_id=ticket_session_id, new_message=content)\n",
        "    async for event in events:\n",
        "        if event.is_final_response():\n",
        "            ticket_result = event.content.parts[0].text\n",
        "            print(ticket_result)\n",
        "            individual_results.append((\"Ticket Searcher\", ticket_result))\n",
        "    print(f\"{'-'*80}\\n\")\n",
        "\n",
        "    # Docs Searcher\n",
        "    print(f\"üìñ DOCS SEARCHER:\")\n",
        "    print(f\"{'-'*80}\")\n",
        "    docs_session_id = f\"{session_id}_docs\"\n",
        "    docs_session_service = InMemorySessionService()\n",
        "    await docs_session_service.create_session(\n",
        "        app_name=\"docs_search\",\n",
        "        user_id=user_id,\n",
        "        session_id=docs_session_id,\n",
        "        state={}\n",
        "    )\n",
        "    docs_runner = Runner(app_name=\"docs_search\", agent=docs_searcher, session_service=docs_session_service)\n",
        "    events = docs_runner.run_async(user_id=user_id, session_id=docs_session_id, new_message=content)\n",
        "    async for event in events:\n",
        "        if event.is_final_response():\n",
        "            docs_result = event.content.parts[0].text\n",
        "            print(docs_result)\n",
        "            individual_results.append((\"Docs Searcher\", docs_result))\n",
        "    print(f\"{'-'*80}\\n\")\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    # Now show what happens in parallel mode\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"üí° EDUCATIONAL NOTE:\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"Above, we ran each agent SEQUENTIALLY to show you their individual outputs.\")\n",
        "    print(f\"In a ParallelAgent, all 3 would run SIMULTANEOUSLY and aggregate automatically.\")\n",
        "    print(f\"Let's now run the actual ParallelAgent to see the aggregated result:\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    # Now run the actual parallel agent\n",
        "    parallel_start = time.time()\n",
        "    events = research_runner.run_async(user_id=user_id, session_id=session_id, new_message=content)\n",
        "\n",
        "    final_response = None\n",
        "    async for event in events:\n",
        "        if event.is_final_response():\n",
        "            final_response = event.content.parts[0].text\n",
        "\n",
        "    parallel_elapsed = time.time() - parallel_start\n",
        "\n",
        "    # Display aggregated results\n",
        "    if final_response:\n",
        "        print(f\"üìä PARALLEL AGENT - AGGREGATED RESULTS:\")\n",
        "        print(f\"{'='*80}\")\n",
        "        print(final_response)\n",
        "        print(f\"{'='*80}\")\n",
        "        print(f\"\\n‚è±Ô∏è  Time comparison:\")\n",
        "        print(f\"   Sequential (showing each): {elapsed_time:.2f} seconds\")\n",
        "        print(f\"   Parallel (actual): {parallel_elapsed:.2f} seconds\")\n",
        "        print(f\"   ‚ö° Speedup: ~{elapsed_time/parallel_elapsed:.1f}x faster!\")\n",
        "        print(f\"\\n‚úÖ Research completed - {len(individual_results)} sources consulted\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "\n",
        "    return final_response\n",
        "\n",
        "def research_issue(issue_description: str, session_id: str = \"research_001\"):\n",
        "    \"\"\"Synchronous wrapper for research_issue_async.\"\"\"\n",
        "    try:\n",
        "        loop = asyncio.get_running_loop()\n",
        "        import nest_asyncio\n",
        "        nest_asyncio.apply()\n",
        "        return asyncio.run(research_issue_async(issue_description, session_id))\n",
        "    except RuntimeError:\n",
        "        return asyncio.run(research_issue_async(issue_description, session_id))\n",
        "\n",
        "print(\"‚úÖ Parallel research function ready!\")\n",
        "print(\"   üí° Shows individual outputs THEN parallel aggregation!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsdHhzGtM5oR"
      },
      "source": [
        "### 4.8: Run Parallel Research Demonstrations\n",
        "\n",
        "**What you'll see in the output:**\n",
        "\n",
        "For educational purposes, the demonstration runs in two phases:\n",
        "\n",
        "1. **üî¨ Individual Agent Responses (Sequential)** - We run each agent separately to show you what each one finds:\n",
        "   - üìö KB Searcher - Results from knowledge base\n",
        "   - üé´ Ticket Searcher - Results from past tickets  \n",
        "   - üìñ Docs Searcher - Results from system documentation\n",
        "\n",
        "2. **üìä Parallel Agent (Actual)** - Then we run the ParallelAgent to show:\n",
        "   - How it aggregates results automatically\n",
        "   - The dramatic speed improvement (3x faster!)\n",
        "   - The final combined output\n",
        "\n",
        "**Why show both?** ParallelAgent doesn't expose individual agent outputs in its event stream - it runs them all concurrently and only returns the aggregated result. By running agents individually first, you can see what each contributes before seeing the parallel aggregation!\n",
        "\n",
        "This verbose output helps you understand what happens \"under the hood\" when agents run in parallel!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xTMJ2dvM5oS"
      },
      "outputs": [],
      "source": [
        "# Demo 1: Research laptop power issue\n",
        "research_issue(\n",
        "    \"Laptop won't turn on after liquid spill. Need to know repair procedures, past incidents, and hardware specs.\",\n",
        "    session_id=\"research_demo_1\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xa9cGXKrM5oS"
      },
      "outputs": [],
      "source": [
        "# Demo 2: Research Wi-Fi performance issue\n",
        "research_issue(\n",
        "    \"Conference room Wi-Fi is very slow during meetings. Need troubleshooting steps and network configuration.\",\n",
        "    session_id=\"research_demo_2\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMr3Z8pWM5oS"
      },
      "outputs": [],
      "source": [
        "# Demo 3: Research email access problem\n",
        "research_issue(\n",
        "    \"User can't login to email despite correct password. Need to understand email system config and past solutions.\",\n",
        "    session_id=\"research_demo_3\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqlTDGCOM5oS"
      },
      "source": [
        "### 4.9: Parallel Execution Key Observations\n",
        "\n",
        "**What you just saw:**\n",
        "\n",
        "1. ‚úÖ **Individual agent outputs (sequential demonstration)**:\n",
        "   - We first ran each agent separately to show what they find\n",
        "   - üìö KB Searcher displayed knowledge base matches\n",
        "   - üé´ Ticket Searcher displayed similar past tickets\n",
        "   - üìñ Docs Searcher displayed relevant system documentation\n",
        "   - This helps you understand what each agent contributes\n",
        "\n",
        "2. ‚úÖ **Parallel execution (actual ParallelAgent)**:\n",
        "   - Then ran all 3 agents simultaneously using ParallelAgent\n",
        "   - All searches happened at the same time (not one after another)\n",
        "   - Results automatically aggregated by the ParallelAgent\n",
        "   - ~3x faster than the sequential demonstration!\n",
        "\n",
        "3. ‚úÖ **Time comparison**:\n",
        "   - Sequential (for demonstration): Shows each agent's work\n",
        "   - Parallel (production use): Dramatically faster\n",
        "   - The speedup is visible in the timing output\n",
        "\n",
        "**How ParallelAgent Really Works:**\n",
        "\n",
        "```\n",
        "Parallel Agent Execution (what actually happens):\n",
        "Time 0s:  ParallelAgent launches all 3 sub-agents simultaneously\n",
        "          ‚îú‚îÄ üìö KB Searcher starts (API call 1)\n",
        "          ‚îú‚îÄ üé´ Ticket Searcher starts (API call 2)\n",
        "          ‚îî‚îÄ üìñ Docs Searcher starts (API call 3)\n",
        "\n",
        "Time 1-2s: All agents working in parallel\n",
        "          (3 concurrent API calls to OpenAI)\n",
        "\n",
        "Time 2s:  All agents complete\n",
        "          ParallelAgent aggregates results\n",
        "          Returns combined output\n",
        "```\n",
        "\n",
        "**Important Note:**\n",
        "ParallelAgent doesn't expose individual agent responses in its event stream - it handles aggregation internally. In our demo, we ran agents individually FIRST (sequentially) to show what each finds, then ran the actual ParallelAgent to demonstrate the speed benefit and automatic aggregation.\n",
        "\n",
        "**When Parallel is Perfect:**\n",
        "- Tasks are independent (don't depend on each other)\n",
        "- Speed is critical\n",
        "- Gathering information from multiple sources\n",
        "- API calls or I/O-bound operations\n",
        "\n",
        "**Cost Consideration:**\n",
        "- ‚ö†Ô∏è Parallel = Multiple simultaneous API calls\n",
        "- 3 agents in parallel = 3 concurrent API calls\n",
        "- Same total cost as sequential, but higher instant rate\n",
        "- Trade-off: Speed vs API rate limits\n",
        "- Worth it when time is more valuable than cost\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ve99G6JxM5oS"
      },
      "source": [
        "## üîÑ Part 5: Comparing Sequential vs Parallel\n",
        "\n",
        "### Performance Comparison\n",
        "\n",
        "| Aspect | Sequential | Parallel |\n",
        "|--------|-----------|----------|\n",
        "| **Execution Order** | One after another (A‚ÜíB‚ÜíC) | All at once (A+B+C) |\n",
        "| **Total Time** | Sum of all stages | Max of longest stage |\n",
        "| **Dependencies** | Later stages see earlier results | All stages independent |\n",
        "| **API Calls** | N stages = N calls | N stages = N simultaneous calls |\n",
        "| **Cost** | Linear (1x) | Higher (Nx but faster) |\n",
        "| **Use When** | Steps depend on each other | Steps are independent |\n",
        "\n",
        "### Example: 3 Agents, Each Takes 2 Seconds\n",
        "\n",
        "**Sequential:**\n",
        "```\n",
        "Agent 1 (2s) ‚Üí Agent 2 (2s) ‚Üí Agent 3 (2s)\n",
        "Total Time: 6 seconds\n",
        "API Calls: 3 (one at a time)\n",
        "```\n",
        "\n",
        "**Parallel:**\n",
        "```\n",
        "Agent 1 (2s) ‚îê\n",
        "Agent 2 (2s) ‚îú‚îÄ All at once\n",
        "Agent 3 (2s) ‚îò\n",
        "Total Time: 2 seconds\n",
        "API Calls: 3 (simultaneously)\n",
        "```\n",
        "\n",
        "### Decision Matrix\n",
        "\n",
        "**Choose Sequential When:**\n",
        "- ‚úÖ Stage B needs results from Stage A\n",
        "- ‚úÖ Order matters for correctness\n",
        "- ‚úÖ Building a pipeline/assembly line\n",
        "- ‚úÖ Want to minimize concurrent API usage\n",
        "\n",
        "**Choose Parallel When:**\n",
        "- ‚úÖ All tasks can run independently\n",
        "- ‚úÖ Speed is more important than cost\n",
        "- ‚úÖ Gathering data from multiple sources\n",
        "- ‚úÖ Have concurrent API quota available\n",
        "\n",
        "### Real-World Pattern Combinations\n",
        "\n",
        "**Fan-Out/Gather (Most Common):**\n",
        "```\n",
        "Sequential [\n",
        "    Prepare Query,\n",
        "    Parallel [Search A, Search B, Search C],  # Fan-out\n",
        "    Aggregate Results                          # Gather\n",
        "]\n",
        "```\n",
        "\n",
        "**Staged Pipeline with Parallel Steps:**\n",
        "```\n",
        "Sequential [\n",
        "    Initial Processing,\n",
        "    Parallel [Validation A, Validation B],\n",
        "    Final Decision\n",
        "]\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC70ei7lM5oS"
      },
      "source": [
        "## üéì Part 7: Student Exercises\n",
        "\n",
        "### Exercise 1: Create a Code Review Pipeline (Intermediate)\n",
        "\n",
        "**Task:** Build a sequential code review pipeline with 3 stages:\n",
        "1. **Syntax Checker**: Verify code syntax is valid\n",
        "2. **Security Reviewer**: Check for security vulnerabilities\n",
        "3. **Performance Optimizer**: Suggest performance improvements\n",
        "\n",
        "**Requirements:**\n",
        "- Use `SequentialAgent` with 3 `LlmAgent` sub-agents\n",
        "- Each stage should provide specific feedback\n",
        "- Test with a sample code snippet\n",
        "\n",
        "**Hint:** Each reviewer builds on findings from previous stage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ny4VbM15M5oS"
      },
      "outputs": [],
      "source": [
        "# Exercise 1: Your code here\n",
        "\n",
        "# TODO: Create 3 reviewer agents\n",
        "# syntax_checker = LlmAgent(...)\n",
        "# security_reviewer = LlmAgent(...)\n",
        "# performance_optimizer = LlmAgent(...)\n",
        "\n",
        "# TODO: Create sequential pipeline\n",
        "# code_review_pipeline = SequentialAgent(\n",
        "#     name=\"code_review_pipeline\",\n",
        "#     sub_agents=[syntax_checker, security_reviewer, performance_optimizer]\n",
        "# )\n",
        "\n",
        "# TODO: Test with sample code\n",
        "# sample_code = \"def add(a, b): return a + b\"\n",
        "# Review the code through the pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJsWTKTMM5oS"
      },
      "source": [
        "### Exercise 2: Add a 4th Parallel Searcher (Beginner)\n",
        "\n",
        "**Task:** Extend the parallel research system with a 4th searcher.\n",
        "\n",
        "**Requirements:**\n",
        "1. Create a \"FAQ Searcher\" agent with mock FAQ data\n",
        "2. Add it to the `ParallelAgent` sub_agents list\n",
        "3. Test that all 4 searchers run in parallel\n",
        "\n",
        "**Hint:** Follow the same pattern as existing searchers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_Yug7AoM5oS"
      },
      "outputs": [],
      "source": [
        "# Exercise 2: Your code here\n",
        "\n",
        "# TODO: Create mock FAQ data\n",
        "# FAQ_DATA = [...]\n",
        "\n",
        "# TODO: Create FAQ searcher agent\n",
        "# faq_searcher = LlmAgent(...)\n",
        "\n",
        "# TODO: Recreate parallel agent with 4 searchers\n",
        "# extended_parallel_researcher = ParallelAgent(\n",
        "#     name=\"extended_researcher\",\n",
        "#     sub_agents=[kb_searcher, ticket_searcher, docs_searcher, faq_searcher]\n",
        "# )\n",
        "\n",
        "# TODO: Test it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da_eiQKKM5oT"
      },
      "source": [
        "### Exercise 3: Fan-Out/Gather Pattern (Advanced)\n",
        "\n",
        "**Task:** Combine Sequential and Parallel agents in a fan-out/gather pattern.\n",
        "\n",
        "**Requirements:**\n",
        "1. Create a SequentialAgent with 3 stages:\n",
        "   - Stage 1: Prepare query (1 agent)\n",
        "   - Stage 2: Search multiple sources (ParallelAgent with 3 searchers)\n",
        "   - Stage 3: Aggregate results (1 agent)\n",
        "2. Test the complete workflow\n",
        "\n",
        "**Challenge:** Show that parallel stage runs faster than sequential would."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtXA9yiLM5oT"
      },
      "outputs": [],
      "source": [
        "# Exercise 3: Your code here\n",
        "\n",
        "# TODO: Create query preparer\n",
        "# query_preparer = LlmAgent(...)\n",
        "\n",
        "# TODO: Use existing parallel_researcher or create new one\n",
        "\n",
        "# TODO: Create results aggregator\n",
        "# results_aggregator = LlmAgent(...)\n",
        "\n",
        "# TODO: Combine in sequential wrapper\n",
        "# fan_out_gather_pipeline = SequentialAgent(\n",
        "#     name=\"fan_out_gather\",\n",
        "#     sub_agents=[query_preparer, parallel_researcher, results_aggregator]\n",
        "# )\n",
        "\n",
        "# TODO: Test and time it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cePg5GnM5oT"
      },
      "source": [
        "### Exercise 4: Performance Comparison (Intermediate)\n",
        "\n",
        "**Task:** Compare sequential vs parallel execution times.\n",
        "\n",
        "**Requirements:**\n",
        "1. Create a simple task that can run sequentially or in parallel\n",
        "2. Time both approaches with the same input\n",
        "3. Calculate the speedup: `sequential_time / parallel_time`\n",
        "4. Analyze when the speedup is worth the cost\n",
        "\n",
        "**Goal:** Understand the speed vs cost trade-off empirically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIGDvoPVM5oT"
      },
      "outputs": [],
      "source": [
        "# Exercise 4: Your code here\n",
        "\n",
        "# TODO: Create 3 simple agents (e.g., summarizers)\n",
        "\n",
        "# TODO: Create sequential version\n",
        "# sequential_test = SequentialAgent(...)\n",
        "\n",
        "# TODO: Create parallel version\n",
        "# parallel_test = ParallelAgent(...)\n",
        "\n",
        "# TODO: Time both with same input\n",
        "# import time\n",
        "# start = time.time()\n",
        "# # Run sequential\n",
        "# sequential_time = time.time() - start\n",
        "\n",
        "# start = time.time()\n",
        "# # Run parallel\n",
        "# parallel_time = time.time() - start\n",
        "\n",
        "# TODO: Calculate and display speedup\n",
        "# speedup = sequential_time / parallel_time\n",
        "# print(f\"Speedup: {speedup:.2f}x\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijkvNyX2M5oT"
      },
      "source": [
        "---\n",
        "\n",
        "## üéØ Part 8: Key Takeaways\n",
        "\n",
        "Congratulations! You've mastered workflow orchestration patterns in ADK!\n",
        "\n",
        "### What You Learned ‚úÖ\n",
        "\n",
        "1. **Sequential Workflows (SequentialAgent)**\n",
        "   - Execute agents in strict order\n",
        "   - Each stage sees previous results\n",
        "   - Perfect for pipelines and assembly lines\n",
        "   - Deterministic, no LLM decides flow\n",
        "\n",
        "2. **Parallel Execution (ParallelAgent)**\n",
        "   - Run agents simultaneously\n",
        "   - ~Nx faster (N = number of agents)\n",
        "   - Perfect for independent information gathering\n",
        "   - Same total cost, but higher instant load\n",
        "\n",
        "3. **When to Use Each**\n",
        "   - Sequential: Steps depend on each other\n",
        "   - Parallel: Steps are independent\n",
        "   - Combine them: Fan-out/gather pattern\n",
        "\n",
        "4. **Performance Trade-offs**\n",
        "   - Parallel is faster, not cheaper\n",
        "   - May need higher API rate limits\n",
        "   - Worth it for interactive/time-sensitive tasks\n",
        "\n",
        "\n",
        "### Production Best Practices üí°\n",
        "\n",
        "1. **Choose the Right Pattern:**\n",
        "   - Need one expert? ‚Üí Hierarchical Routing\n",
        "   - Multi-stage process? ‚Üí Sequential\n",
        "   - Parallel info gathering? ‚Üí Parallel\n",
        "\n",
        "2. **Optimize Performance:**\n",
        "   - Cache frequently used results\n",
        "   - Batch similar requests\n",
        "   - Use cheaper models where possible\n",
        "\n",
        "3. **Monitor Costs:**\n",
        "   - Track API usage per workflow\n",
        "   - Measure time savings vs cost\n",
        "   - Adjust based on SLAs and budget\n",
        "\n",
        "### Real-World Applications\n",
        "\n",
        "**Sequential Workflows:**\n",
        "- Document processing pipelines\n",
        "- Multi-stage approvals\n",
        "- Manufacturing processes\n",
        "- Data ETL pipelines\n",
        "\n",
        "**Parallel Execution:**\n",
        "- Multi-source research\n",
        "- API aggregation\n",
        "- Competitive analysis\n",
        "- Risk assessment from multiple models\n",
        "\n",
        "**Combined Patterns:**\n",
        "- E-commerce: Search (parallel) ‚Üí Filter (sequential) ‚Üí Rank (sequential)\n",
        "- Healthcare: Gather (parallel) ‚Üí Analyze (sequential) ‚Üí Recommend (sequential)\n",
        "- Finance: Fetch data (parallel) ‚Üí Calculate (sequential) ‚Üí Report (sequential)\n",
        "\n",
        "\n",
        "### Resources üìö\n",
        "\n",
        "- [ADK Sequential Agents](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/)\n",
        "- [ADK Parallel Agents](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/)\n",
        "- [ADK Workflow Patterns](https://google.github.io/adk-docs/agents/workflow-agents/)\n",
        "- [OpenAI Rate Limits](https://platform.openai.com/docs/guides/rate-limits)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lpRib4UJNob2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}